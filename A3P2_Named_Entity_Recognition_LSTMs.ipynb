{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nadaz10/NER-using-NN-and-LSTM/blob/main/A3P2_Named_Entity_Recognition_LSTMs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6czvz5VKO5M"
      },
      "source": [
        "# Notebook for Programming in Problem 2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5o8HI5JqTvU5"
      },
      "source": [
        "## Learning Objectives\n",
        "In this problem, we will use [PyTorch](https://pytorch.org/) to implement long short-term memory (LSTM) for named entity recognition (NER). We will use the same dataset and boilerplate code as in Programming Problem 1 of Assignment #3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObrHyvWvTyGZ"
      },
      "source": [
        "## Writing Code\n",
        "Look for the keyword \"TODO\" and fill in your code in the empty space.\n",
        "Feel free to change function signatures, but be careful that you might need to also change how they are called in other parts of the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "r6YTnpgbFdMI",
        "outputId": "fa892048-2ca1-417b-efca-0071fe11e76c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Apr 27 14:52:19 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   56C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi # you may need to try reconnecting to get a T4 gpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnYMKJlKNXYe"
      },
      "source": [
        "## Installing PyTorch and Other Packages\n",
        "\n",
        "Install PyTorch using pip. See [https://pytorch.org/](https://pytorch.org/) if you want to install it on your computer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-dRVuiP_JVdT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93c33a83-634f-4741-bcc9-4e1a6da92881"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext) (4.66.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.31.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext) (1.25.2)\n",
            "Requirement already satisfied: torchdata==0.7.1 in /usr/local/lib/python3.10/dist-packages (from torchtext) (0.7.1)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.7.1->torchtext) (2.0.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchtext -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPsFH637OpLy"
      },
      "source": [
        "Test if our installation works:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "c62StNb2NvKk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4ae5408-1fc8-4d80-ec95-87c4df2dacde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch successfully installed!\n",
            "Version: 2.2.1+cu121\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Multiply two matrices on GPU\n",
        "a = torch.rand(100, 200).cuda()\n",
        "b = torch.rand(200, 100).cuda()\n",
        "c = torch.matmul(a, b)\n",
        "\n",
        "print(\"PyTorch successfully installed!\")\n",
        "print(\"Version:\", torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qaC8sxcqkGX"
      },
      "source": [
        "Also install [scikit-learn](https://scikit-learn.org/stable/). We will use it for calculating evaluation metrics such as accuracy and F1 score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "i5Y2xB_uqqM9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "280d9632-99a8-4319-f181-e8a06ff0d5ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.4.0)\n",
            "Installing collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "Successfully installed scikit-learn-1.4.2\n"
          ]
        }
      ],
      "source": [
        "!pip install -U scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhV4CYivRbt4"
      },
      "source": [
        "Let's import all the packages at once:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "EjRM4cCFRh-d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchtext.vocab import Vocab, vocab\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "import re\n",
        "from collections import Counter\n",
        "from typing import List, Tuple, Dict, Optional, Any"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yn1bIPjAN-9V"
      },
      "source": [
        "## Long Short Term Memory (LSTM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJOKIneRTrTH"
      },
      "source": [
        "### Data Loading\n",
        "\n",
        "We will use the same dataset for named entity recognition in Assignment #2. First download the data and take a look at the first 50 lines:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "lWqz7kDxSqeb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbcad5ba-03ac-400f-b1bb-1bb4dfc26188"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EU NNP I-NP ORG\n",
            "rejects VBZ I-VP O\n",
            "German JJ I-NP MISC\n",
            "call NN I-NP O\n",
            "to TO I-VP O\n",
            "boycott VB I-VP O\n",
            "British JJ I-NP MISC\n",
            "lamb NN I-NP O\n",
            ". . O O\n",
            "\n",
            "Peter NNP I-NP PER\n",
            "Blackburn NNP I-NP PER\n",
            "\n",
            "BRUSSELS NNP I-NP LOC\n",
            "1996-08-22 CD I-NP O\n",
            "\n",
            "The DT I-NP O\n",
            "European NNP I-NP ORG\n",
            "Commission NNP I-NP ORG\n",
            "said VBD I-VP O\n",
            "on IN I-PP O\n",
            "Thursday NNP I-NP O\n",
            "it PRP B-NP O\n",
            "disagreed VBD I-VP O\n",
            "with IN I-PP O\n",
            "German JJ I-NP MISC\n",
            "advice NN I-NP O\n",
            "to TO I-PP O\n",
            "consumers NNS I-NP O\n",
            "to TO I-VP O\n",
            "shun VB I-VP O\n",
            "British JJ I-NP MISC\n",
            "lamb NN I-NP O\n",
            "until IN I-SBAR O\n",
            "scientists NNS I-NP O\n",
            "determine VBP I-VP O\n",
            "whether IN I-SBAR O\n",
            "mad JJ I-NP O\n",
            "cow NN I-NP O\n",
            "disease NN I-NP O\n",
            "can MD I-VP O\n",
            "be VB I-VP O\n",
            "transmitted VBN I-VP O\n",
            "to TO I-PP O\n",
            "sheep NN I-NP O\n",
            ". . O O\n",
            "\n",
            "Germany NNP I-NP LOC\n",
            "'s POS B-NP O\n",
            "representative NN I-NP O\n"
          ]
        }
      ],
      "source": [
        "!wget --quiet https://princeton-nlp.github.io/cos484/assignments/a2/eng.train\n",
        "!wget --quiet https://princeton-nlp.github.io/cos484/assignments/a2/eng.val\n",
        "!cat eng.train | head -n 50\n",
        "#The --quiet is used to suppress output message"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVt1a6nzWsiF"
      },
      "source": [
        "Each line corresponds to a word. Different sentences are separated by an additional line break. Take \"EU NNP I-NP ORG\" as an example. \"EU\" is a word. \"NNP\" and \"I-NP\" are tags for POS tagging and chunking, which we will ignore. \"ORG\" is the tag for NER, which is our prediction target. There are 5 possible values for the NER tag: ORG, PER, LOC, MISC, and O.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "WnNfOBUYJvVW"
      },
      "outputs": [],
      "source": [
        "# A sentence is a list of (word, tag) tuples.\n",
        "# For example, [(\"hello\", \"O\"), (\"world\", \"O\"), (\"!\", \"O\")]\n",
        "Sentence = List[Tuple[str, str]]\n",
        "\n",
        "\n",
        "def read_data_file(\n",
        "    datapath: str,\n",
        ") -> Tuple[List[Sentence], Dict[str, int], Dict[str, int]]:\n",
        "    \"\"\"\n",
        "    Read and preprocess input data from the file `datapath`.\n",
        "    Example:\n",
        "    ```\n",
        "        sentences, word_cnt, tag_cnt = read_data_file(\"eng.train\")\n",
        "    ```\n",
        "    Return values:\n",
        "        `sentences`: a list of sentences, including words and NER tags\n",
        "        `word_cnt`: a Counter object, the number of occurrences of each word\n",
        "        `tag_cnt`: a Counter object, the number of occurences of each NER tag\n",
        "    \"\"\"\n",
        "    sentences: List[Sentence] = []\n",
        "    word_cnt: Dict[str, int] = Counter()\n",
        "    tag_cnt: Dict[str, int] = Counter()\n",
        "\n",
        "    for sentence_txt in open(datapath).read().split(\"\\n\\n\"):\n",
        "        if \"DOCSTART\" in sentence_txt:\n",
        "            # Ignore dummy sentences at the begining of each document.\n",
        "            continue\n",
        "        # Read a new sentence\n",
        "        sentences.append([])\n",
        "        for token in sentence_txt.split(\"\\n\"):\n",
        "            w, _, _, t = token.split()\n",
        "            # Replace all digits with \"0\" to reduce out-of-vocabulary words\n",
        "            w = re.sub(\"\\d\", \"0\", w)\n",
        "            word_cnt[w] += 1\n",
        "            tag_cnt[t] += 1\n",
        "            sentences[-1].append((w, t))\n",
        "\n",
        "    return sentences, word_cnt, tag_cnt\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "WLMGYSZ7KxzP"
      },
      "outputs": [],
      "source": [
        "# Some helper code\n",
        "def get_device() -> torch.device:\n",
        "    \"\"\"\n",
        "    Use GPU when it is available; use CPU otherwise.\n",
        "    See https://pytorch.org/docs/stable/notes/cuda.html#device-agnostic-code\n",
        "    \"\"\"\n",
        "    return torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "wVHAOb7iMPwC"
      },
      "outputs": [],
      "source": [
        "def eval_metrics(ground_truth: List[int], predictions: List[int]) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Calculate various evaluation metrics such as accuracy and F1 score\n",
        "    Parameters:\n",
        "        `ground_truth`: the list of ground truth NER tags\n",
        "        `predictions`: the list of predicted NER tags\n",
        "    \"\"\"\n",
        "    f1_scores = f1_score(ground_truth, predictions, average=None)\n",
        "    return {\n",
        "        \"accuracy\": accuracy_score(ground_truth, predictions),\n",
        "        \"f1\": f1_scores,\n",
        "        \"average f1\": np.mean(f1_scores),\n",
        "        \"confusion matrix\": confusion_matrix(ground_truth, predictions),\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7s830dhbnj1L"
      },
      "source": [
        "## Long Short-term Memory (LSTM)\n",
        "\n",
        "Now we implement an one-layer LSTM for the same task and compare it to FFNNs."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM Cell\n",
        "![LSTMcell.JPG](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAeAB4AAD/4RDgRXhpZgAATU0AKgAAAAgABAE7AAIAAAAHAAAISodpAAQAAAABAAAIUpydAAEAAAAOAAAQyuocAAcAAAgMAAAAPgAAAAAc6gAAAAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAExlbm92bwAAAAWQAwACAAAAFAAAEKCQBAACAAAAFAAAELSSkQACAAAAAzA1AACSkgACAAAAAzA1AADqHAAHAAAIDAAACJQAAAAAHOoAAAAIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAyMDI0OjA0OjI3IDE0OjI1OjUzADIwMjQ6MDQ6MjcgMTQ6MjU6NTMAAABMAGUAbgBvAHYAbwAAAP/hCxlodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvADw/eHBhY2tldCBiZWdpbj0n77u/JyBpZD0nVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkJz8+DQo8eDp4bXBtZXRhIHhtbG5zOng9ImFkb2JlOm5zOm1ldGEvIj48cmRmOlJERiB4bWxuczpyZGY9Imh0dHA6Ly93d3cudzMub3JnLzE5OTkvMDIvMjItcmRmLXN5bnRheC1ucyMiPjxyZGY6RGVzY3JpcHRpb24gcmRmOmFib3V0PSJ1dWlkOmZhZjViZGQ1LWJhM2QtMTFkYS1hZDMxLWQzM2Q3NTE4MmYxYiIgeG1sbnM6ZGM9Imh0dHA6Ly9wdXJsLm9yZy9kYy9lbGVtZW50cy8xLjEvIi8+PHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9InV1aWQ6ZmFmNWJkZDUtYmEzZC0xMWRhLWFkMzEtZDMzZDc1MTgyZjFiIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iPjx4bXA6Q3JlYXRlRGF0ZT4yMDI0LTA0LTI3VDE0OjI1OjUzLjA1NDwveG1wOkNyZWF0ZURhdGU+PC9yZGY6RGVzY3JpcHRpb24+PHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9InV1aWQ6ZmFmNWJkZDUtYmEzZC0xMWRhLWFkMzEtZDMzZDc1MTgyZjFiIiB4bWxuczpkYz0iaHR0cDovL3B1cmwub3JnL2RjL2VsZW1lbnRzLzEuMS8iPjxkYzpjcmVhdG9yPjxyZGY6U2VxIHhtbG5zOnJkZj0iaHR0cDovL3d3dy53My5vcmcvMTk5OS8wMi8yMi1yZGYtc3ludGF4LW5zIyI+PHJkZjpsaT5MZW5vdm88L3JkZjpsaT48L3JkZjpTZXE+DQoJCQk8L2RjOmNyZWF0b3I+PC9yZGY6RGVzY3JpcHRpb24+PC9yZGY6UkRGPjwveDp4bXBtZXRhPg0KICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICA8P3hwYWNrZXQgZW5kPSd3Jz8+/9sAQwAHBQUGBQQHBgUGCAcHCAoRCwoJCQoVDxAMERgVGhkYFRgXGx4nIRsdJR0XGCIuIiUoKSssKxogLzMvKjInKisq/9sAQwEHCAgKCQoUCwsUKhwYHCoqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioq/8AAEQgBFwNjAwEiAAIRAQMRAf/EAB8AAAEFAQEBAQEBAAAAAAAAAAABAgMEBQYHCAkKC//EALUQAAIBAwMCBAMFBQQEAAABfQECAwAEEQUSITFBBhNRYQcicRQygZGhCCNCscEVUtHwJDNicoIJChYXGBkaJSYnKCkqNDU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6g4SFhoeIiYqSk5SVlpeYmZqio6Slpqeoqaqys7S1tre4ubrCw8TFxsfIycrS09TV1tfY2drh4uPk5ebn6Onq8fLz9PX29/j5+v/EAB8BAAMBAQEBAQEBAQEAAAAAAAABAgMEBQYHCAkKC//EALURAAIBAgQEAwQHBQQEAAECdwABAgMRBAUhMQYSQVEHYXETIjKBCBRCkaGxwQkjM1LwFWJy0QoWJDThJfEXGBkaJicoKSo1Njc4OTpDREVGR0hJSlNUVVZXWFlaY2RlZmdoaWpzdHV2d3h5eoKDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uLj5OXm5+jp6vLz9PX29/j5+v/aAAwDAQACEQMRAD8A+kaKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigApM0teZ/EXWL+Dxv4b02xu5rdJJg8gjbG/nGD6jFZ1Kipx5mdOFw8sTU5Iu2jf3K56YKKBRWhzBRRRQAUUUUAFFFFABRXnfgjxLqmsePvENpd3PmWlu2IYtoHl4JHB/CvRKzp1FUjzI6cTh54ap7Oe9k/v1CikzS1ocwUUZozQAUUUUAFFFFABRSMwVSSQAOpNIrq6gqQQe4NADqKKzNW8Q6Voce/Vb6G2HYO3J+gpNpK7KhCU5csFd+Rp0VnaRr+ma7p5vdKu47i3UkM6n7pHXPpWXf/ELwxp8CTT6vAyNIYx5R3nI65A7e9S6kErtmkcPWnJxjBtryOloqk2s6cvk772BfPAMW6QDeD0xSatrNholibzVLpLaAcbnPU+g9afNFK9yFTm2oqLuy9RWFovjHQ/ETPHo2oRTzKMmM/K35HnFcVdeOPFfhPX4x4xsIDpdy+1JbYZ8rn1747jis5V4RSfTuddLAV6spQStJdHo36Lqeok4qK5uobS3ee5lWKKMbndzgKPc1598QfGEk3hu6g8KTTTToqvPd233bdM926ZPHFV/F+sNqPwOivRN5rXMUIkf1ORuz+IqJ4iMea3RXNqOW1ans3LRTly+aPSre4iuoUmt5FlikXcjochh6g1LXO+AoFtvAmjxpyv2VDz7jNdFW8XzRTPPqwVOpKC6OwUUUVRmFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABXk3j0/8Xe8N7umV/ma9ZryT4nr5HxC8M3ecDzFUn/gX/wBeuTF/w16o9jJ9cS13jL8j1K7v7WwgeW8uI4I0G5mkYAAVz9n8SPC19qCWVvq0TSudqZBCsfQE8VhfFLwY2s2P9s2AaS7tEy8BYlJYxzjHrXHeI5/Duq+B9IudBsLe0vpLyOKSOIYdGHUHvUVa9SEmrKy/E6MHl2Gr0oycpNu60taLt18me3/brX7Ubb7RF54XcY943Y9cU+C6guVJt5o5QpwdjA4NeP8AxV0GazvNK1fS45Eu7pBazyRZyxIAGcflR4P0258FfFCHRlld7e9tN7huhbGc49jmn9ZkqvI46d/UhZXSnhfbwq+9Zvlt23/4Bv8Aiv4rRaJrElhplib82pH2uTdhY/b61veB/GI8Y6dc3Qs2tRDN5YBbO4YzmuO134c3lhpWuzQatELG5ZrqRWgzKxHO3dnpVP4X+K9N0PQotOdZrnULy6JW3gjLMAeNx9BWUK1WNflquyZ2VsHg6mXuphY3nFpN69rtvoj2WmSyxwqWldUUdSxwKcDkVyXjbwQfF8lp5mqz2dvBnzIYxkSe/XrXfOUlG8VdnzlCFOdRRqy5Y97X/A4j4a6rZWvxC8QC6uoozdS7YNzAeYdx4HrW/wDEzx5caDJHo+juIr+YBnnkHyxKe47Z/lXPfB3TrceK9cKxrKlriOGR1BK/MenoavfFLSbux8SWHiiGzF9aQgJcQsu4YHqPQg15cZVFhLrTX8Ln11anhZ5zy1FdKKsn1dlZGR4Jn8SX3jBrq31i71OwskZ7qTJMcpx9xQepzW/a/Fm60+/ki8XaNLp0UiGS3YKckdgQfX1rZ8KeO/CN5HBYaU0WnyyHAtDHsO49h2Ncd8aJ7q78RaXpcERclN0QC5LuzYx+lNuVGjz053/HczgqeNxzo4mjyq3o0l17am7rnjPxK3w/TxBZWaabuuQVWT52MPYkds1gW3xe1sanFf3lnGNFaTyWCoc5A5Ib19q7fx3a3LfC+5t4rZ55xDGDHGuTkEZwBXE654V1GH4P6LY2mnzS3bTiWZFTLIWB6j8adf26neEnor/MMv8A7PnRSrU1eU2t9o2vf/Ilk+KXiqTfrVtpCf2FHLsOUOSP97PX8MV6vo2q2+t6PbajZnMNxGHXPUe1Zf8Awj0Y8AnQ4olUGz8sJj+Lb/jVf4caVe6L4IsrHU4TDcR7t0ZOSoLHFdVGNWErTd01+J5GNqYStS5qMFBxlbTrHu/M6qiig11njHhWteIfE3inxfceF7a9228t2YwI02lUHXJHOKp6dfeM9L1S88LaBqBkazd5MkBjtXrgnsfSu98I+CdQ0r4gavrOoxxiGVm+zMGBLbmyTjt2p/hrwHfaV8RNS128mjaCUv5AU5Lbzk59MYrxlh60mpNu7bv5I+4lmWCpxnShGLjGKaVt59STwh46uNd8FX93PGG1TTo2EsajG8gZBx715Hpup2Woaldal4rs77Vp5ATD5bfKr9gQOQPpXovw5tGt/iN4ujiX/RVl2kEcZ3E4/KtHU/hNYy6o1/oWo3WkTO25hByoPsO1XOnWrQhLtv8A5mNDFYHA161NqynZprppe2mqJ/hf4bn0vwjMdUhMUupSNK8B42IRgDHbivJk0Kxk1fxOudtvpsUjQAeu/C19AaBpl5pOlrbahqc2pyqxPnzIFOPTism1+Hmh2z6uxjllGrH9+Hf7oznC46c81tWwnPGMUtjjwec/V61arNu82tvJ6/geQ6f4KfUvh1eeJ9QupfMhT/REJzhFOPw9sVvXl8+q2Xw/k1n99BOSs6zcrJxgEivU28MaYfDB0AQsunmPyvLVyDt69apeIPA+leINDtdLmV7eG0I8gwHBTAxj8qlYRwjaHZfNlyzqGIqp1rpczs0tk1bT8zgdIsdP1L40RzeEbZINP02Mi5lhHyMxBGB25/pU/wAY73Vbu6sdCsbKWWCXEpKRlvMfoAD2x/WvR/D3hzTvDOmLY6VD5cYOWYnLOfUnvWoRk1r9WcqTg3a+9jj/ALVUMZHERjzKCsubf1fmc34X8PfYvAVpo2qQoxa32XCAAAkjkcfzrzHxt4H1Hwv4UuVt9aabRROGjsnX5gSfX2r0fxv45tPB9io2ie/mH7i3B6+59BXl3iHR/FOr+F7jxN4pupIo0Km3sunDMBnb2HPfmsMX7Pk5Iq7S+71PRyZYhVo4irJRhOWz15n5L9T0nwH4o0q80bTNItLgz3kNonmqiEiMgD7zdBXaVyPwwggj+H2mSQwxxtJFukKLgu3qfU111d9G/s1c+cxvIsTNQTtd7hRRRWpyBRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFeaeJviVqkniyTwp8PtHXWtVt13Xk0kmyC09mb19qAPS6KwPCN54lvNNkPi/S7bTrtJNqLbXAlWRcD5vbnPFas+qWNtqFvY3F1DHdXW7yIWcBpNoycDvigC1RRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABXm3xW0PUdSutDutLtJLloLkBxGudoyDk+3FdjfeLfD+m6pFpt/rFnb3szBY7d5gHYnoMVsVnVpqrHlZ1YTEywtZVYK7V/xViOMEwoJB820bh+FcRc/CzSpvF0GtQSvBGknmyWir8ruOh9q07DxzY6l8QdQ8J20Mj3GnwLNNOMbAT/D65rqKJ04TtzK9iaOJrUG3Sla+jGsobG4A45GRWfNoVhPr0GsSQ5vYIzEj56KfatKsvxLqq6L4bvdQJwYYiV/3u361U7JXl0IpKcpqEN3p955v8UfHUpkuPDei84T/AEyYc7R3Uf1NbHwe0ayt/CEWprAv2u5Zt0xGTtBwAPQVwdnp3k/CrWfEV5813qcwRGbrt3c/ma9X+G1t9m+HulJ/eh3/AJ15mH5qlfnn208j6rMfZ4bLfq9DRKdm/wCZpa/K51FI670KnuMU6ivVPkDlPBngmLwi1+6XTXL3ku8sy7do7CupZVdSrAEHggjrTqKmMYxjyrY1q1qlabqVHdsz4ND0q2uftEGm2sc2c+YsKhh+NWpLW3lmjmlgjeWP7jsoLL9D2qaimopbIhzlJ3bEo7UtFMkSilooAM0ZoooASilooApWWlWenS3MlnbrE91KZZmHV2Pc1cpaKSSWw223diUUtFMQlFLRQAZpGOFJ9KWkPSgDxrwZZr41+Jeqa3q371LCT9zE3IByQv4ADP1rs/iphfh1qGfWMD/vsVw5nufhZ8Qrue4t3l0bUWLb1HQE549wSeK0fiT470PWPBJtNJvVuZrmRD5a/eQA55HavJjUhGhOMtJa3Ps6mHrV8woVaSvS92zWyS39LdTrfhgMfDnSc/8APM/zNdbWD4J06TSvBel2c3Ekduu4HsSM1vV6VNWgl5HyuKkpYicl1b/MKKKK0OYKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigDH8W64nhvwhqmsPz9itZJgPUheB+dcj8EfD7aV8PodUvT5mp6651C7mI5YucqPpg5/E11fjHw6nizwhqWiSSmEXsDRCQDOwnofzrzfTLT41aHpVrpFpb+H7mCziWCK5dyNyKMDIyOwFAHsdeQeNwIv2kPAcg5LwXKkHp93/AOvXV+C7Xx/BNeT+N77TLhHj/wBHt7NGUo/uT2ryTxPN4/v/AI2+EjqVrpWk6mUnFlmQzxgY+Ytjrx0oA+j6K562svFNr4Xuo5dVs73WnUmCVrcxwo2OAQCSRWR4a0Px8NQjvPFviazaJW3GysLXCsPQs3I/CgDV8X+NrDwbBbyaha3tybhiqLaW7SHj1x0rzTw/44v/ABR+0NaeVHqem6Y2lOFs71SglYbjvC/lz7V7dXkusHb+1J4e/wBrSJx+jUAetUUySeKFd0siIPVmApY5ElQPE6up6MpyDQA6iiigAooooAKKKKACiiigAooooAKKKKACik3DuaaZo16uo+rUAPoqA3lsv3riIfVxUMmsabF/rL+2X6yrTUZPZAXaKy28TaIn3tWsx9Z1/wAaibxf4eT72tWI+s61ao1HtF/cxXRs0VgP478LR/6zxBpy/W4WoX+I3g9OviTTf/Ahar2Fb+R/cF0dLRXKt8TvBa9fEmn/APf4VGfip4JXr4lsPwlFV9Vrv7D+5i5o9zrqK40/FrwMOviOz/77ph+L/gUf8zFan6Gq+p4n/n3L7mHNHudrRXDn4x+BR/zH4D9AaafjN4FH/McjP0Rj/Sn9RxX/AD7l9zDmj3O6orgH+NngZRn+1Xb/AHbdz/Sq7/HbwSv3Lq8f/dspP8KX1PE/8+39wc0e56PRXmQ+PHhWVd1rDqc47GOyc5/Sj/hdNvKubHwrr90e2y1xn86tZfin9gXPHuem0V5ivxQ8S3X/AB4/DrWj6ecAlI/jT4k3C/6F8P1jJ6G4vAv9Kf1Cut7L/t5f5hzo9PorzBb74w3q5TS9D0/PaWYyEfkaVfD/AMWrzJuvFWk2QPa3tixH50fU0viqxXzv+SDm8j06ivMD8N/Gd2c6j8R74e1vbKtOX4Q3jj/TPHevzeu2XZ/I0vYYdO0qy+SYc0ux6ZuHrRketeZ/8KWt+/i3xJ/4HNXJeOPCE3gaXQ7jR/E+uS3d3qMcIW4vCy7cjOR34reng8NVlyQra/4WJykt0e9UUiAhRu5OOTS15ZoFFFFABRRRQAUUUUAFcH8VfGN94a0ez0/QEEmt6zP9lsg3RCern6Cu8rg/ib4J1HxRDpmpeHLqO21rR7j7RaGYfI/GCpoAZ4J+FGj+G4EvtWiXV9fkbzbjULob2Mn+znoBXa6jczWmmzz2lq95NGhKQRkBpD6AnivLk8X/ABeSMW8ngKzkuBwZhfAI3v7fnVi08PfEvxPe20vi7WLTRdPilWV7LTM+bJtOQpfpj1xQB5xanxwnx4vUtYbDwrqOvWwk23LeeCq9wR/GfSvafDuiap4bla88V+M59UeQbRHNHHDEhJ7Ack/jR46+HWk+Oo7WS8nuLG+szm2vrV9skftn0rA0f4I6Nb6hDea5rWreIJYHEkaXt0TGGHIO3JoA9QByMjpXJ/Ey1lu/h/qSQAsyqGIHoDzXWAAAAcAU2WNJomjlUMjDDKRwRUVI88HHub4et7CtCr/K0/uPANY1y2vvhHoekWrj7SZ/LkiB5BHH9a9x0K0+waDZWuMeTAq4/CuWsfhPoFh4iXVY/OYI/mR2zEFEau5AxXNhqU4Nyqb6L7j1c0xmHrQjTw97Xcnfu/8AIKKKK7DwwooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAq3+nWmp2j2uoW8dxA/VJFyK52z+Gnhay1FL2HTF82Nt6B3LKp9cGusoqJU4Sd2jeniK1KLhTm0n0TADHSiiirMAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAK8t+MPhvW577QPFvhezF9f+H7gytaj700ZxkD1+7+tepUUAcN4H+Id34yv3gbwtqelRQxZlnvFCqH/ALg9a7mjijNAHJ+N77xrZraL4F0iz1BpC32h7q4Efl9MYB655/KvN5/h38UfFPjC18Ravq+maBd2kLQRPZr5jKjZzjqM817nkUbhQFzzrTfg1pSsJfE+q6r4inP3heXTLF+CKcV39lZW2nWcdrYQJb28Ywkca4Cipt1G6gVxaKbvA6kfnSGVB1dR9WFAx9FQteW6DLzxAe7iqc3iLSLf/X6lap9ZRSckt2XGnOWkU38jSormrn4h+FbXIl1y0yOyvmsm4+L3haI4huJ7k/8ATGFjWbrUlvJHTHA4qfw039x3dFecN8XYJQf7P0DVLkdiIsZpp+JOvSjNv4Kv2B6bsio+s0u/4M3/ALKxnWKXq0v1PSaK81HjfxrPxbeCpUP/AE0cj+lH9ufE26ysHh6zts9Gkkzj9aX1iHRP7g/sysvilFf9vI9JyKw/Glw1v4J1iWKdoJEtJGWSNsMp29Qa5E6B8SdU4vdftdPRuogXJFYnjTwBJovgfVtV1LxJqV7Lb2ztsZyEY46EZ5FdGFqTnXglB7rf1JqYShTi+eur+SbH+DPhvH4k8E6Zq2p+JvEJnvIRJIsd8VXOT0reX4L+H8fvtS12b/f1J63vhvD5Hw20GM9rND+fNdPXq4jHYlVpqM7K7/M8qMI2POx8EvCB5ljv5f8ArpeuamT4K+BF+/o3m/8AXSdz/Wu+oxXL9cxP/Px/eVyx7HEL8HfAK9PDdr+LP/jUy/CbwKnTw1Z/juP9a7HFGKn61iHvUl97Dlj2PG/i58PvC+kfDu4vtK0S0tZ4LiFzIinO3eNw+hFdtZ/DzwZPZwzp4b0/EsauP3Q7jNM+LVqbv4T+IY0Us4s3ZQPUc1p+Brz7f4B0O5677GLP1Cgf0qfrFb+d/ex8q7Fdfh34QXp4c07/AL8CpV8B+FV+74d04f8Abuv+FdDRR9Yrfzv72LlXYwV8FeGVPGgacP8At3X/AAqRfCPh1emhacP+3ZP8K2qKXt6v87+9hyrsZI8L6Cv3dE07/wABU/wp48O6IOmj6ePpap/hWnRS9rU/mf3jsigNF0xfuadZr9IF/wAKedMs/LZUtIEyCMrEox+lXKKnnk+rCx5h8DmJ8MavYzgGSy1e5jGRyFL5Fem7a8t+FLmy8fePdIb/AJZ6is6j2Zf8TXqlS7vcYYpMD0paKACiiigAooooAK8n+Kf+mfErwJpxPyteNKV9cV6xXj/xQ+0H4t+D104qNQ2v9m83/Vhs/wAVdmCn7Oq52vZPb0HGn7RqN0vXY9fyKNwrzp9J+Jtwx36zp1uD/wA80zTF8FeOLg5vfGbID2hj/wDrV5ftpdIM9H6jSXxV4/i/0PSNwFNaaNfvSIPqwrzr/hV+pzf8fnjPVJD328f1py/B+xcf6XrmrT+uZyKPaVekPxBYfBr4q/3RZ3UurWEAzNeW6f70grNufG3hu04n1qzU+nmg1z8Pwc8Lp/rku7j/AK6T5zWlbfDPwlbY2aNC5Hd2J/rReu+iXzDky6O85P0SX6la6+LPhK2+7qJnPpDGW/lWdJ8Y9KfIsNM1K7bsFgIz+ddhbeGdEsx/o2k2cf0hB/nWhHbQxf6qKOP/AHVApctd7yS+Q/a5fH4acn6y/wAkect8SfEN2QNM8GXrZ6NLkClHiT4k3P8AqPC1vCD0MklelAUuKPYze82H13Dx+DDx+bb/AFPNBJ8Vbv8A5YaZZ57kg4/Wj/hH/ibdjFx4itLYHr5SdP0r0vFGKPq66yf3h/aUl8NKC/7d/wAzzUfDTXLs/wDE18ZXsgPVYgV/rXSeFvBkPheWeSPUb68eZQD9plLAY9BXTUVUaFOD5ktTKtmGJrQdOctOySX5BRRRW5whRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAGV4hutWtNLMug2Ud7dBh+5kk2Ar3OfWuTPibx6/yxeD40b+81xxXoNGKzlByd1Jo6qNeFONpU1L1v+jPPRd/E+4+7YaVbA/3pM4pTZfE6b72oaTD/ALsZNeg4oxUew7yf3m6x7W1KH3Hnf/COfEaX/WeKrSPnokH/ANag+DvHMh/e+Ndv/XOAf4V6JRR7CPd/eL+0KvSMV/26v8jzv/hAvFD/AOu8cXf/AAGIUh+G2sSZ87xrqTf7q4/rXotFL6vT6/mx/wBpYno0v+3V/kecj4VTN/rvFurP64fH9aevwjsj/wAfGvatL9ZyK9Doo+rUuwf2njFtP8F/kefr8HfD5P7661KX1DXJ5q1D8JPCMRBbTmlI7ySk121FUsPSX2UTLMsZLeo/vOag+H/ha2bMWh2uf9pSf51rW+i6ZaAC20+1ix/diUf0q/ijFWqcI7JHNPEVp/FNv5sYsaKPlUL9BilxTsUVZiJRgUtFABXA/GuTyvhLrPP30VPzYCu+rzr468fCTUif+ekP/oYrswKviqa80RP4Wdb4Ri8jwbo0f92xh/8AQBWxWb4dOfC+ln/pzh/9AFaVc1R3m35lLYKKKKgYUUUUAZfia1+2+FdTtj/y0tZF/wDHTXK/BG8N58H9D3HLwxtC/wBVY13N2u+ynQ/xRsP0rzX4BTA+ALy3HH2XVrmID2DUAen0UUUAFFFFABRRRQAUUUUAeTeFybT9pLxXbg7UuNPhmIx1bOM16zXkw/0f9qRgvH2rRuffaTXrNABRRRQAUUUUAFFFFABXkfxCOPjr4C/3n/nXrleQ/ET/AJLp4C/3n/ma9DL/AOM/8MvyZFTY9eoxSd6WvPLCiiigAooooAKMUUUAFFFFABRXMfELxc3gjwXea3Ha/a5INoSEttDEnHJra0a/fVNEs76WBrd7mFZDE3VCRnFAF2iiqX9saf8A2x/ZX2yH7f5fm/Z9437P72PSgC7RRRQAUUUUAFFFFABRRRQAUUUUAFFFcPo/jDUL74va/wCGLhIVstPtYJoCq/OS45yaAO4ooooAKKKjuJltrWWd87Y0LnHoBmgCSisDwV4utPG3hqLWbCGWCKSR4/LlxuBVip6fSt+gAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKM0AFFFRz3ENrCZbmVIo16u7BQPxNAElFc34h+IHhnwte2trrmqRW0t0A0YPICk4DMR0GeMmti91ew07SX1O+u4YLKNPMad3AQL65oAuUVg654v03RfBFx4p3fbNPhgE6tbkHzVJAG09OcitawvE1DTre8hBEdxEsihuoBGaALFFFFABRRRQAUUUUAFFFFAGPpvijTNW8RarotnKzXukmMXSlSAu9dy4PfitivKvAZ2/Hj4iJ/e+yN/5DFeq0AFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFedfHYZ+Eep+zxH/x8V6LXnHx4cL8I9RB6vJEo/wC+xXbl/wDvdP8AxIifws7Lww27wjpB9bGH/wBAFatZfhldnhPSVPUWUI/8cFalck/iZS2CiiipGFFFFACEZUg9xXlXwOPkr4ssl+7BrcxA/wB4k16seRXk3wlb7N8Q/iFYHgJqKSAfVf8A69AHrNFFFABRRRQAUUUUAFFFFAHkfik/Yf2lPCdx90XVjNCT6n0r1yvIfitIbH4o+ANRP3RetCT9a9eoAKKKKACiiigAooooAK8g+Ibf8X38Bj0Zz+tev14/8QTn49+BQexb+dejl38WX+GX5MzqbHsAooorzjQKKKKACiiigAooooAKKKKAPNfj4cfCTUT/ALcX/oVdrolzDD4Z015pEjDW0eC7Afwj1rg/2h7hbb4RXbP0e4iXHrzn+lcn4U8Fal8XdPTX/GF3eafpCwiHS9OtpSm1VGPMPrzzQB74CCMjpXh+oXyaL+1VDe6neW0dndaWyxsXACAADDH1yK0/hpqOqWuo678NvEt7NJdWCE2d7uPmSQOMA5PcVxHxI+GOheA9Y8MazOlzqmnve+TqT30pfcG6EnsOf0oA9iu/i34ItJDGdftp5B1S3Jkb8hXU6ZqMGrabBfWm/wAmdA6eYhVsH1B5Fc54eXwLDfrp3hqLSftSx+bsto1LqvqSOf1rraACqGp65pejQmXVdQt7RAMkzSBf51LqUV1PpdzFp862908bLDKy5CNjgkV4fp/hvU/C9495468ETeK7jeWbVIbj7Sceoib7o9sUAet6R458Ma9e/ZNH1yyvLjGfKilBYj6U3xx4sh8F+GX1aeBpwJY4ljU4LFjisDw6vgXxnqFjqehW8Fve6RIX8iOAQSxMRjDrgHFUfj7/AMk4g/7Clt/6EaAPSoJfOt45cY3oGwe2RmpKgsj/AKDB/wBcl/lXMeNPiDa+D7yxsv7NvtUvr4M0NtZpliq9TzQB11FcND8Q5PEXhOPUvBGly6neSzfZ2t5T5f2V+/m56AVxfir4n+NvhnLCfF9rpOpR36t9nSxco0TjoGB6rz1oA9mvL610+3M99cRW8Q6vK4Ufma8Us/F2hWn7S2p3A1OB7e90+GFHjbeGkGBt4710Om/DabxnZLqvxNvTqktyqyQ2NvIUtrZTyAAPvH1NYlr4f0nwv+0tpllo9hBZ2smiuRHGvG4MOee/HWgD2wHIzRRRQAVBex+bYXEf9+Nl/MU65uYbO1lubmRY4YULyOx4VQMkn8K83f40WWp3Mlv4R8Pav4h2nb51rDtjJ/3mxke9AEP7PUu74ZNCesF/cJ9P3hNep14b+z1e662i3sMelwppx1KZpZ5J8OjE5KhR6Vt/GPxn4i0a60vw74Vty91rCuGmhG6aNV+8UXoTjNAHqQurcu6CaMtGMuu8ZX6+lV9O1nTtWWQ6ZewXYjba/kyBtp9DivJPh38MJXn1TUdXi1LTra/s/sYhubkm5mBOXlkPRSegHYVgfF7SbL4dXGnz/D43Gl6pdwPHcw2fIe2UfNIw/vDsfrQB7TdeNfD9pc3tvJqMTTWFu1xcpGd3lIvXOOh9qxtX+LPhnSfCNj4g8+S5t9R/49IYUJll9cL2x3qx4I8NeH7X4f21vpEKz2eoWweWaRdz3O8cs5PUnNeQ/BLwsbnxBrl5rh8618Nmawson5WIksznHrg/rQB7RD4/8OyeD7bxNcajFa6ZcKGSSc7ef7uPX2rZ0rVrDW9Oiv8ASbqK7tZRlJYmyDXz38D/AAIfFsP9r+J911o2l3EsWmWMnMZYuSzkdDycV2nge1Pgb4za34Qtfl0nUrcapYw54hOdrqPbJ/SgD1yiiigArzb40eKtQ8HaNoeqWF69pCNWhjvNqg74TksDn2Fek15P+0Fo954g8I6PpVjbyTfatXhSQxrnYpBGT6DmgDk7+88deIPCd78ToNWm06G0YT6bpKfckt1bDGT13Dn6VsW3xq8Tanpr+JNI8GyXHhi2YLPOZcTNj77KncCu68caJeN8JNT0Xw7blrn7D9nghTuOAQP+A5q74C0F/D/w70fRr2JBLbWaRzpgYLbfm+vOaANDR/Eml654bh12xukbT5YvN81jgKAOc+mOc15D4h+L2qeJfiXpPhj4aOs9ulwjX16q7ldM5YD0UDOT3NdJ8L9FGi61408MNEJNIt9QD28UgyqpKgYpg9uR+dZuiaD4p+G3ifWzpPhm31rS9TvGuo7m3kWOaMN/yzIPYflQB0vxm1PU9E+FOp6no1y1vdWphcSJ1x5igj9a8v8AtviLwDp/hv4ka/rd5drq8+NWsyxMUcUi7owidioH516x450HU/HvwrvNJgiGmX1/HHmO4bPlEOrEEr7CofGnw8bxb4R0Xw+bqOG1srqCW5DKT5scYIKj0JzQBhaD8XNXvPEOkJr/AIafStG15mTTbp5cuzAZAde27tVrx+03iP4i+HfBUxUaTdQTXmoRMuftCKdqp7c8/wD6qs/E/QpdWm8GWNhEwaHXIZyyL/q441Zm+g4Aqf4geENb1LWNJ8R+Drm3g1nTFki23I+SaOQYIPuDyKAMP4W6Rp/iPwLq2ja9bR6jHY31xpYnnUNI8KtlBv68buPpXE+DfDmo+L/FV54B1rUvtnhfwjcvuRXO66yxESMfRcH8sV7T4B8JDwZ4PtdJab7RcAtLcz4/1srHcx/M4+lUfAHw2svAdzrF1Bdy3t1q1yZpppRggZJC/huPPvQB4n49k8S+BvhXqXgC+024uLA3aLY6qn+ra3Z94Rj2YEAY9K+ktJiFjoNnFIQoht0VieAMKK8b/aD8WWNzaaV4S0t1v9Zl1SCV7KI5O0ZwpPYkkVpwfDvxn43xc/ELxFLp1o4G3SNLbaFX0Z+5/OgD1DTNd0vWWuV0q+guzayeVP5LhvLfrg471frG8M+E9G8H6UNP8P2SWkGdzbeWdvVj3NbNABRRRQAUUUUAFFFB6UAeUeCHX/hoH4gkH5VjtQx9D5Yr1GC7trksLa4im2/e8tw2Pyr5oi0/xF41+OnjPRvD17Jp2m3VzGNTvYhh0jjULsU+pOfyrofFfhKP4J3+i+K/CVzeCwFylrq1vNKXEsbH7598/qRQB7N4p1z/AIRvwvf6v9mkujaQmQQxDLOfT/69U/APiSfxf4F0zXrq2W1lvYy7RK2QuGI4P4Vl/FXxFp+j/DLVZby42C9tJILchSd7shwOKo/A3VLbUPhRpENqJQbOERSF4yoLZJO0nqOeooA9EorF8VeIX8NaHJfQ6Zd6nKCFjtrRNzux6fQe9c74V1rx/r+pR3Ws6HaaFpOTmGaQvcOMeg4Xt1oAq6b4w1W4+P8AqXheWRf7Mh0tZ449vIfcOc/jivRq8ctz9n/a1nVuPP0Mbffk/wDxNex0AFFFFABRRRQAUUUUAFFFFABRRRQAUUUZoAK8v+P8m34ZNH/z1u4V/wDHxXpzSIgy7qo9ScV5P8frmCfwHbJDPHI39oQ5CMDjn2r0crV8ZT9SKnws9N0dPL0OxT+7bRj/AMdFXaraeNum2w9IU/8AQas1wS+JloKKKKkAooooAK8j8Cj7N+0J45t14E8UU+PU/KK9cPSvINJH2L9qjVYxwLvSEfHrg/8A1qAPX6KKKACiiigAooooAKKKKAPHvj+DDD4RvU4e31lMH68V7CDkZFeRftFKV8FaXcD/AJYapCxPp8wr1ezk82xgk/vxq35igCaiiigAooooAKKKKACvHviBz8fvA2P9r+Zr2GvE/iVqcGl/HTwre3QkaG0t3kcRIXYjPYDk16eWr97L/DL8jOpse10ted/8LhsZf+PHw7r9z6bbFl/nTf8AhaeqSD/Rfh74jl/7YqP5mvMND0aivOx4/wDF8wzB8OtTX/rtMi/1qN/F3xKlP+ieAYFB/wCfi/C/yoA9IorzYav8XJ2+XwzolqPV7/d/IUpPxelB2r4egJ6ZLNigD0ijNeaDSfi/cMRP4i8P269vLs3J/nTh4K+Ic/N18QPJJ6/ZrJf60Aek0ZHrXmo+GPiOVf8ATviPrUxPUJHGg/Sj/hTFpOD9v8UeI589cX5TP5UAbfxE8J6d458OJpOpaitpCtzHOzBh8wU/d5PetGPxB4Z0Kxhs/wC1rC3hgjCInnr8oAxXMx/BHwiABdDUr0dxc3zuD9ea0bP4R+BLE7oPDNnu7s4Lk/maAOJ1Txf4QtfjPZeJoPEVhJbpp0ltcrDJvcvn5eB14rs7PxR4O+JsN1oSo2oQ7N8sU9uyqR6gnvW9aeE/D9jj7HoenxEdCtsmfzxWnDbQwZ8mGOPPXYoH8qAMjw14N8P+ELd4fDulwWKyffKDLN9Sea3KKKAPJfHGu6nqXxKj8It4g/4RfTPsyzfawAJLxj1RGPAx3qC/8N3vhu2a90X4qPB5Y3eXqciSxN9T1/KvTNe8MaL4ns/suv6bBfQg5AlXlfoeorAsvhB4DsLhZ4PDdqZFOVMhZ8fgTigDyTRPGlxrPxO8P6lqlvb6YYZpLe51u1DC21IY+VM9OvOTXfftBQ3dz8LgumRtLcf2hbmMIu7nJwfzxXoF9oGlajo7aVd2EEliy7fI2AKPoB0/CrkNtFBbRwRr+7jUKoPOAOlAHil9ovj34e6Db+Lh4muNbMCrJqmmzIAhjOM7PQrWp4/1aGHUPA/xAh3HS4Ztty4GfLjlXhj7A9TXput6Wmt6FeaZLI0cd3C0TOo5AIwcUy10DT7bw7Doht0lsIoBB5Ui7gygY5FAHn/wcZdR1DxfrlkMabqOru9oVGFkUAAsPxrkPiDqGj2fxh19vGULyWx0QQaZGYi/mO687B67q94sNPtNLsY7PTreO2tohhIolwqj6Us+n2d1PHNc2kE0sX+reSMMyfQnpQBy3wottRs/hho0GsLIlysA+SX7yr/CD74xWF480PVIvir4Q8TaTZSXaQs9neCIcpG2SGPtz+lenUUAFFFFADZI0miaOVFeNwVZWGQwPYiq4todO0149Pto4UjQlIoUCjOOgAq1RQB5n8CNJu9L+H0jajbyW891fTzFJFw2C5AOPpXQ+OfAlt4ztrSRLybTtT0+Qy2V9B9+Jj1+oPpXVYpaAOQ8Kab450+78vxRrGmalZKhCvDAyTE9ie1ct8TvAXifxD4xtNS8MvaiKfTpNMunuGx5CO2WdR3OOK9YooAzvD+jQ+HvDlhpFsS0VlbpAhPcKMVG3h6xh07UrbTYI7JtREjTSRLgtI64Ln3rVooAwPBPhaPwb4QstDhl88WyndJjG9iSScfU1DP4T8/4mW3ippl22+mtZLFjnLSbi2fpgV0tFABRRRQAUUUUAFFFFADEhjjd3jjVWkOXYLgscYyfXgU+iigAooooAKKKKACvO/ih4x1LT5LLwn4QG/xJrWRC3UWsX8Up/XH0NeiV5N4GjXV/j3461W8+efTxBZWwb/lnHg5x9SoNAHJav4CsPB/j34dadDI15ql3qMt1fX0xzJO6qpyT6DnAr6FUYUfSvJfFJGpftNeELSP5v7O06e6kHpuDKP6V63QAUUUUAFFFFABRRRQAUUUUAYfh/wAIaT4ZvdUu9KidJtVuTc3LO27c/t6Dk8e9ct8dLWW++Fd3aW8JmmuLm3jjUDJyZlAr0WmvGkgAkVWAIIDDPI6GgDKvtAttQ8Lvo14omia28jLjJ+7tz9a8w+FHi8+ErWH4eeKrS8h1WxuWt7aRYGaOeNmJVtw4A5/LFem+JrTXrvTkTwxqNvp90JAWkuIPNVlwcjHbtXInw78TnlEj+KdGDAYDrpx3AfXNAHo/BorzlvBfjy7/AOPrx/Jb/wDXrZKP50i/C/W5MG6+ImuSHOTtVEH6UAWdY8DX9z8aND8Y2EsS29raSW12jH5mUhtuPX7xrviQOpxXnf8AwqaSTi58Z+IJR3xcBc/kKj/4Unozn/SNe8RS+udTcfyoA9Ea4hT780a/VgKgk1bToh+9v7VP96ZR/WuIi+CfhRABK+q3H/XbUJG/rVgfBjwLnMuiLP8A9dpnb+tAHRT+LfD9spabWbFAPW4X/Gs6b4meDLdSZvEunIB/02FQwfCjwLbMDD4ZsAR6oT/M1ow+B/C8BBi8P6cMf9Oyn+YoAxJfjJ4FjH7vXYZ/aFWfP5Cqb/G/wn0t01S5bsItPkOf0rto9D0qEgw6baRkdNkCD+lXI4kiGI0Vf91cUAeeH4vwy/8AHh4V8QXZ7BbMrn86aPiX4luTix+G+uf705RB/OvSKKAPN5PGHxHlx9i8Axrn/n4vgv8AKhdR+Ld1j/iR6FYg92uzJj8hXpFFAHnDWXxduSP+Jt4dsx3xbu5pP+EM+IN9n+0fH4tc8EWFko/9Cr0iigDzZfgzYXcnma/4j17VJP8AavDGp/4Ctcj8W/BWieD/AAJAuh27xG51KHzXklZ2fB45Ne715N+0Cd3hbR4O8uqRCvSyr/fafr+hnU+BnqNl/wAeEH/XJf5VYqKBdlvGv91QP0qWvOluzQKKo6zrNjoGkz6lq1wtvaQLukkboBVm2uIry0iubdg8UyCRGH8SkZB/KkBLRRRQAV4/qZFn+1bpMhOBd6S8f1IBx/OvYK8d+Jn/ABL/AI4fD/UVGBLM9s59iRQB7FRRRQAUUUUAFFFFABRRRQB5b+0PHn4S3EwGTBdwSfTD16FoEvn+G9MlHO+0ib80Fch8b7U3Xwd11Qu4pDvA+hrb+Hlybz4c6DO3VrKMfkMf0oA6SiiigAooooAKK85+LXinVfDsnhiDRbgQPqOqLBKxXOUxkj8a9GoAK8i1LT5L39p3TXnuMx2+nGaJMdMDkV6Tq3iTR9DeNNX1G3s2k5QTOF3fSvO4NUsNV/aKsZ9Nu4bqP+yZAWicMM16mAjOKqTtpyS1M520Xmer7RS4ooryzQKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAK8f8SzS/DD4uyeL5onfw74giS31CRFz9lmQYVz/skfzPpXsFRXNrBeW7wXcMc8LjDRyKGVh7g0AeS/DInxn8T/ABL4/wAObHjTdMcjAeJcbmH1IB/E16/UNraW9jbpb2UEcEKDCxxKFVfoBU1ABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFcf8AEfwYfGGiW627hbywnF1bKxwjuB91vY12FFaUqsqU1OG6E1dWZ5t/wn3i7S1Ca34DvZWXh5bCVZEPuM07/hbyr/rfCWvIe4+zZr0fFFdHt6D+Kkvk2ieV9zwT4tfEpNc+G2o2Mfh/V7XzdgM1xBtRRuHU10eg/FY23hzTYF8I67IIrSJN6QfK2EAyPatL48H/AIs5rX+6mP8AvoV1ng3cfA2h785/s+DP/fsVPtaF7+z09WOz7nIf8LgRf9Z4S15P+3bNNPxosF/1vh7XU+tmxr0vFGM1XtsN/wA+f/JmK0u55qvxx8Nr/wAfFnq0PrvsX4/SuB+J3xA0LxLrHhW/0aa436ZqKyzebbsm1McnkV9CNbwv9+JG+qg1C2mWD/fsrZvrCp/pT9phP+fb/wDAv+AFpdzjl+MvgY/e1tE/30YVYi+LfgaX7viK0H+8xFdG/h/R5f8AWaVZN9bdP8Kqy+DvDkxzJodgf+3df8KrmwL+zL71/kFpmcPid4LPTxJY/wDf2g/E7wWP+Zksf+/tWf8AhAPCv/QA0/8A78Cue8d6J4W8JeBtU1qPw9pzS2sBaJWgGC/ap/2L+9+Ae+az/FLwUgyfEdj+ElVn+L/gZOviG2P0JNQeBvDGj6x4I0nU9X8O6bFfXVuJJlS2AGT6D6YrpU8J+H4/uaLYD/t3X/CnfArpL71/kL3/ACObb4z+Bh01lX/3Y2NRP8bfBSfdvrh/9y1c/wBK7FNA0iP7mlWS/S3X/CpV0rT1+7YWq/SFf8KTlgukJfev8h2n3PJvGfxe8La74N1bS7aPUpWubZ41Is3ABx9Ky/hh8WrfTPhvpGmvour31xawmNngtyVbBPQ17h9gtNhX7LCFYYIEY5pbOxttPtUtrGCO3gT7scShVH4Cp9phk7qm2vOX/AC0u55x/wALT127bGmeANZk9Gl2qKG8X/Eq5X/QfAsUJPe6u8V6diir+s0UrRor5tv9Q5X3PMftPxeuVyLLQ7LPZpS5FMOkfF64bJ8QaPbD0WAtXqOKKPrrStGnFfIOTzPmz4raH41s7vwq3iHxNBdmXUwlu0EG3yHx97nrXorfDvxrcH/SviLej18qBRWd+0CoGn+Fpj/yy1mI/mRXpXiLxHpvhbw/PrOsTeTaQLuZsZJ9AB3NSsZVTbSWvkg5Uec33wKXWgp8QeLNT1Fl+6ZET5fpXb+FPAmheELOCLSrKJZ449jXRQeZJ6kmtXQ9asvEOiWuraXL5tpdRiSJ8YyKv0VcdiasFTnN8q6dAUIp3QUUUVxlhRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFeS+N/Enij4deOk1+7lk1HwfebYriELk2J6bh7UAaPx7OPg7q/v5Y/8fFdNoupWmifDbTb/AFKZYLW20yGSWRuigRiuQ+N2oWuqfAy9vtPmWe2ufJeKRDkMC4rldZup/iNq3hz4eaTKRplnZW9zrU0Z7BFxHn+n0oA9a8GeOdF8d6XJfaBM8kcMnlyJIm10PbI9xXRVnaToGl6Esg0ixhtPOC+Z5S437Rhc/QVo0AFFFFABRRRQAV5Z+0NdeV8Lzag4N5ewRfUFxkV6mTjrXkn7RURbwBZXAHywalAzH0G4CgD07RrcWuhWFuowIraNAPooFXagsJBLpttIpyrxKwI75AqegAooooAKKKKACiiigArya9+KXiDwf4rltvHmhC20Ka5MVrqdudyqO26vWaz9c0PT/EWj3GmavbpcWtwpV0YfqPQ0AeW/tBTRXXgTRr21lWSL+04JEdDkMCRgg1neM5JPir4/03wLaO/9ladGtzq0qHHzbeEz61yvxJ0HxD4I+H914Zm86/0lL2KfSb0nJi+b/Ut7+leufB7wXL4V8ILdarl9Z1Qi4vZW5bJ6Ln2FAHV+FvDtr4U8M2Wi2DO9vZpsRnPJGc81rUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFVNU0y11jS7nT9QiWa2uYzHIjDOQRVukYkKSoyccD1oA+T/ABPf3Hg7wj4m+F+pyzSstxFNopwWMkbODtH+exr2z4M/D8+CPCAl1H59X1HbNdyNyV4+VPwFZXh74fap4k+JV1418e26RSWkhi0uxGCqIp4dvX1FetUAFFFFABRRRQAUUUUAYXjTQZ/EvhC/0u0vJbKeaP8AdzwthlYcj9a818Oz3HxV+E+reDdcmFv4g00/ZZ3kGTvU/JJj04r2evFfiGr/AAz+Jlh4/sopDpl+PsurxxLn6Pj/ADzigDu9S1yP4c/DOO6124SaXT7RYspx50gGAFHvUfwvj1uXwiuqeJ7iSS+1OQ3XlOeIEb7qD8K4HRdL1L40eLo/EmvwzWnhPT5M6dYyDBumH8bD0r3BVCKFUAADAA7UALRRRQAUUUyWaOCIyTOsaLyWc4A/GgB9FIrBlDKQQRkEd6WgAooooA4zxv4aufE3iDw1E0W/TLS8a5u/QlV+QH8a7MdKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAK5vx34ytPAvhebWbyF7gI6xxwRnDSMxwAK6SvJfjWxv9Y8FaD/AAX2sIz+4X/9dAHe+D/Fth4z8Px6ppu9BuMc0Mgw8Mg+8jD1FbteY+BVSy+M3jixsji0byJ3jA+VZSOcfUc16dQAUUUUAGKKKKACkJCqSxwB1Jpa5X4m6m+kfDHX72Jiskdm+wjsSMUAdPDNFcRLLBIksbfddGBB/EU+vJf2cdSlu/hgLK63CewuGjKueQrAMv8AM161QAUUUUAFRXFrBeQtDdwxzxN1SRQyn8DUtc5qni37F4s03Q7PT5b97st58sDgi0Ud39KAOhjiSGNY4kVEUYVVGAB7CnUZozQAUVz/AIm8deHPB7W6+ItTis3uD+7VuSR64Hb3rZs7621Czju7GeOe3lUMkkbZVh7GgCevPPjq0i/B3WmhYqQi5IOOM13WoahbaXp099fSiK2t0Mkkh6Ko6mvE/iV8YfCfif4e6xpGj/b7ya4tysckVoxjB9S3YUAekfC7V/7c+GGhXrMWdrVVYnrlfl/pXW14P+zr4o1e58H2mjwaFLLZW87rLqLTKEUHnAXqTXvFABRRRQAE4GT0qnHq+nTTeTDf2skucbFmUtn6Zrlfix4gtND8BXcd3dTWkmof6JBNCMsjtwD9K5iH4E+HbnwjbtbpNYa19nVhewXLEiXGd2e4JoA9dorgfhJ4ovNd8NT6frbZ1fRp2s7snq5X7r/iK0Pid4sXwd8P9R1IN/pBj8q3Xu0jcDFAGR4b+K0PiT4p6p4UsrItb2CE/bFbO5h1GPSvRa8++Dng9PCvgK1mvI1/tO/BuruZlG4l+cE+gpuofG/wbp2rSWMl1cyrC/lzXUNuzwRN6FxxQB6HRUFle22o2UV5YzJPbzKHjkQ5DA9xU9ABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUGgArxP4361beHfiD4G1a+3GC0mllYKMkkYxgetWvFWgfGSXxdJdeHddszpfmhooCwjAX+6wxzXK+LfD/AIgh+J/ge98e6pDqb3epBBaxR4ggXI4A7k9/pQB6d8J9EvrTRb3X9bjMeqeILg3kyN1jTpGn4LXe7h615X8VPGuv6TqA8M6FbiCbUrCWSzvEb5xKnJQDpkjp7msfwt8M7DxR4RsNf0PxXrtvqFzEHa5N0W2yD7wKHjhs0Ae0zzxW0DzXEixRRqWd3OAoHcmqdxrumWmiNrFzexR6esfmm4ZsLt9a8JvdX8U6l4+0n4YeOb+A25mE817E2038IBKxsOxJGPeug+LKRN4w8OabrlteDwjDG0s0VlAzrLIuNiMF6CgC8f2g/DY1OGIWGpGwuJRDBf8AkYjlfPQDqR710/jz4jWPgdLWA2k+panetttbC2+/JjqfYV5Q19p/xK+Onh/R4dMudO0jQ4GuEt5ofK8wgZB2dhwBW42qWVt8ePFeua/IqxaDpC/ZxJzsB6kD1OcUAem+C/Ftp418NRatZRvDl2jlgk+9DIpwyn6Vz3xycp8HNdx/FEF/M1W+DOm3th8N5b2SHyrrVbqe/jik4wHOVB9K4T4oQ/FW5+HurTeJJ9HttMVMy29sN7MM8YagDsvhFbLp+panBGMRz6fp9zwP4jEQf5V6gJY2kKK6l1GSoPI/Cvnv4d+APFPi3Q01a68a3tlZTxRwItogRpY41wBk9hkj8K9h8IeBdK8GxS/2e1zPcTgedc3Uxkd/xPQe1AHS0UUUARXSSyWkqWziOZkIjcjIVscGvE/CWgP4S+Pdpp32+a9u7rS5J9TnZjiWQnIOOw9BXuNeQ+Cpor748eN9WvZUQWEcVpGzsAFXAOcn8aALHx01PWvDGk6V4p0O8kQabdqJrTdiOcNwNw781yktx488F6bpfxA1jXJb+3vZkbUtNI/dwQyfd2/QGr37QmpJ4l+GsQ8Nzf2hCmpLFO1uCyhh0GR15x0rrfEGkyn9nq40/UkLTpowDjuGCD9RQByWqa1ZP+0BBFrmivqNprdjFbac7qGjWNuWcA/UA1h31zqPgvR/iJ4Y0O7litdNRL2yKtzArEZUHsKh8Ta5/wAIt4i+Geo38Us8ttpLHyI13O7EDauPfiu48LeAdU1Twl4p1TxRGI9X8URMfI/54R4+RPr0oA6qbxPFZfBxNfvdlyE0tZXEgyJG2Dr65NYngXVdP8c/BeW6t7C0tJpbaaGeK3iCqrgHp+lecaTrl/4x8CaL8MrS2lGp29z5OqsyELDBE+SSffpXZzeEvFvw/wDEl+/w/sLfUNF1ZBvs5ZNgtZsY3j2oApfsvwyweCdVSQEIt+VX6gYNe3147+zuLm20TxDp18UNxa6o4k2dNzcnHtmvYqACiiigDyv9oKy8/wCH1veld8dhfwzSL/sbua9I066gudHtbm3K+RJAroQeNuBTdZ0i117RbrS9Qj8y2uozHIvsa8jh8G/FHRtJk8IaNqVjJobZjh1KZv38EJ6rjucUAanwlb+0vGnjjXbVQLC71Hy4XH8ZQYY/nWP45kb4g/HDRfB8OX03R8Xt/joW6gH9K72ODS/hR8L5Njf6Pplszs7dZZPU+pJrlvgPoNwdDvvGGsKTqfiCdp9z9Viz8ooA1Pi38QrHwV4ffTX8xL7UbWRLQonyg4wAT261q+CvBml6d8NbHR5rSOSOe1Bud6AmRnGWJPc815P+0vHG/iXwrJdSTG2EhV4ooSxPzA5B6E9sV00/ivx14vtV0fwR4duNFsiohbVdS+VkQDBKr64oAu/AueS3sPEOgCUy2mj6k8NqTztQ87fwr1aua8CeC7TwN4cXTbWRriZ3Mtzcv96aQ9WNdLQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABXkHxxHk6t4HvV4aLWkH5g/wCFev15F8f/AJNO8Ky901uL+RoA3Pi34SvNd0K11bQYw2t6LOLu0HdwPvJ+Iqj8B49Q/wCEM1C51CylsFu9UnnhtpVIMasQSMHtnNen0AYoA+WvilFdP+0XBHbo/wBukktDZkDnG7kj9a+pCARyM/WqE+g6XdazBq1xYQSahbqUhuWTLoD1ANW7i4itLaSe4kWOKJSzuxwFA7mgDxybUbTSv2or+71GeO3gi0JXeSQ4CgFia4XxfFd+N/Fx8fab4dvLrwtbvHBdIjFZL+NGyXC91FLeS6T8V/2ibBrm2uItFngaOKQEqL0RZOf90nivpu2tILO0jtrWJIYIlCJGgwqgdgKAOAsvjb8PmsogusLasqhRayQssiYH3duK474s+OrvxH8MdWbSNNms9F2BJb+/jKGYk4CRp15Pc17N/YOkmfzjplmZf7/kLn88VhfEvwa/jjwDe6DbSpbyS7Widh8qspyPwoAl+GmB8MvD+0AD7FHwB7V1FZPhbR28P+FNN0l5BK9nbpEzgcMQOTWtQAUUUUAFefa78F/C+v8AiafWrsXkUl0QbmKC4ZI5iO7AV6DRQBR07RdO0nSodN0+zhhs4QAkKoNo/wDr+9XJEWRCkihlIwVIyDTqKAPF/ilbw23xp+Hd35aj/SDEeO2eBXtFeN/HFTD4o8CXa/eTVQufqK9koArw2Fpb3Ek8FtDHNL/rJEQBn+p71YIyKKKAOU8IeBofCWsa9e293JMusXQuDEwAERx0FdXRRQAUUUUAFFFNlLiJzEAXwdoPc0AeL/F69m8aeNNG+G+lOSs0i3Wpsv8ABGvIBr2Kxs4dPsILO1QRwwRiNFHYAYFedfDDwFqmi69rfijxW6PrGqTsAqncIogeMH3r03FAHjP7RW37D4T/AL/9sx7fzFeyIPlGeuOa8a+Op+3+J/A2joMvLqYl/AY/wr2YUALRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUmaM0ALRSZozQAtFJmjNAC0UmaM0ALRSZozQAtFJmjNAC0UmaM0ALRSZozQAtFJmjNAC0UmaM0ALRSZozQBm+JNXOgeG77VRbvc/Y4WlMSdWA64ryD4seJNK8ZjwRp/h+8ivZL7VI51WJgSqAc7gOnXvXt7qskbI4DKwwQRkEVy+jfDfwp4f1+XWdJ0eC3vZM/vFH3M9do7Z9qAOropM0ZoAWvKvipe3fiTxJpHw70qZov7TPn6jKh5S3Xkj8a9UzXkmnypaftR6kuoHEl1o6CzLcZAbJA9+DQBn+KNMtNC+Ovw8s9LhWC3it5YUjUcBRivbK8a1eRfEH7UWjW1s3mpolg8s5HSNm6A+/T869kzQAtFJmjNAC0UmaM0ALRSZozQAtFJmjNAC0UmaM0AcD8UfBepeL28OvpJhDadqS3ExlbHyY5x7139JmjNAC0UmaM0ALRSZozQAtFJmjNAC0UmaM0ALRSZozQBzOt+BdP13xpo3iS8lmFxpAYQxKfkYnufpXT0maM0ALRSZozQAtFJmjNAC0UmaM0ALRSZozQAtFJmjNAC0UmaM0ALRSZozQAtFJmjNAC0UmaM0ALRSZozQAtFJmjNAC0UmaM0ALRSZozQAtFJmjNAC0UmaM0ALRSZozQAtFJmjNAC0UmaM0ALRSZozQAtFJmjNAC0UmaM0ALRSZozQAtFJmjNAC0UmaM0ALRSZozQAtFJmjNAC0UmaM0ALRSZooAZmjNFFABmjNFFABmjNFFABmjNFFABmjNFFABmjNFFABmjNFFABmjNFFABmjNFFABmjNFFABmjNFFABmjNFFABmjNFFABmuH+IXw8XxkbK/wBO1CTSdb05i1pfRdVz1B9RRRQA74efDyDwRDd3N1dvqes6g++8v5R8zn0HoK7bNFFABmjNFFABmjNFFABmjNFFABmjNFFABmjNFFABmjNFFABmjNFFABmjNFFABmjNFFABmjNFFABmjNFFABmjNFFABmjNFFABmjNFFABmjNFFABmjNFFABmjNFFABmjNFFABmjNFFABmjNFFABmjNFFABmjNFFABmjNFFABmjNFFABmjNFFABmjNFFABmjNFFABmjNFFABmjNFFABmjNFFABmjNFFABmjNFFABmjNFFABmjNFFABmjNFFABmjNFFABmjNFFABmjNFFABmjNFFABmiiigD/9k=)"
      ],
      "metadata": {
        "id": "FNdAvzMagzO8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "to7DnWNiY5ZS"
      },
      "source": [
        "### Data Loading **(4 points)**\n",
        "\n",
        "Like before, we first implement the data loader. But unlike before, each data example is now a variable-length sentence. How can we pack multiple sentences with different lengths into the same batch? One possible solution is to pad them to the same length using a special token. The code below illustrates the idea:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "J5oVgqE7JaJp"
      },
      "outputs": [],
      "source": [
        "# 3 sentences with different lengths\n",
        "sentence_1 = torch.tensor([6, 1, 2])\n",
        "sentence_2 = torch.tensor([4, 2, 7, 7, 9])\n",
        "sentence_3 = torch.tensor([3, 4])\n",
        "# Form a batch by padding 0\n",
        "sentence_batch = torch.tensor([\n",
        "    [6, 1, 2, 0, 0],\n",
        "    [4, 2, 7, 7, 9],\n",
        "    [3, 4, 0, 0, 0],\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udC0SMjkKaCN"
      },
      "source": [
        "We implement the above idea in a customized batching function `form_batch`. Optionally, see [here](https://pytorch.org/docs/stable/data.html#loading-batched-and-non-batched-data) for how batching works in PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "sACcGN4XYMgj"
      },
      "outputs": [],
      "source": [
        "class SequenceDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Each data example is a sentence, including its words and NER tags.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, datapath: str, words_vocab: Optional[Vocab] = None, tags_vocab: Optional[Vocab] = None\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Initialize the dataset by reading from datapath.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.sentences: List[Sentence] = []\n",
        "        UNKNOWN = \"<UNKNOWN>\"\n",
        "        PAD = \"<PAD>\"  # Special token used for padding\n",
        "\n",
        "        print(\"Loading data from %s\" % datapath)\n",
        "        self.sentences, word_cnt, tag_cnt = read_data_file(datapath)\n",
        "        print(\"%d sentences loaded.\" % len(self.sentences))\n",
        "\n",
        "        if words_vocab is None:\n",
        "            words_vocab = vocab(word_cnt, specials=[PAD, UNKNOWN])\n",
        "            words_vocab.set_default_index(words_vocab[UNKNOWN])\n",
        "\n",
        "        self.words_vocab = words_vocab\n",
        "\n",
        "        self.unknown_idx = self.words_vocab[UNKNOWN]\n",
        "        self.pad_idx = self.words_vocab[PAD]\n",
        "\n",
        "        if tags_vocab is None:\n",
        "            tags_vocab = vocab(tag_cnt, specials=[])\n",
        "        self.tags_vocab = tags_vocab\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Sentence:\n",
        "        \"\"\"\n",
        "        Get the idx'th sentence in the dataset.\n",
        "        \"\"\"\n",
        "        return self.sentences[idx]\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        \"\"\"\n",
        "        Return the number of sentences in the dataset.\n",
        "        \"\"\"\n",
        "        # TODO: Implement this method          ########## DONE\n",
        "        # START HERE\n",
        "        #raise NotImplementedError\n",
        "        return len(self.sentences)\n",
        "        # END\n",
        "\n",
        "    def form_batch(self, sentences: List[Sentence]) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        A customized function for batching a number of sentences together.\n",
        "        Different sentences have different lengths. Let max_len be the longest length.\n",
        "        When packing them into one tensor, we need to pad all sentences to max_len.\n",
        "        Return values:\n",
        "            `words`: a list in which each element itself is a list of words in a sentence\n",
        "            `word_idxs`: a batch_size x max_len tensor.\n",
        "                       word_idxs[i][j] is the index of the j'th word in the i'th sentence .\n",
        "            `tags`: a list in which each element itself is a list of tags in a sentence\n",
        "            `tag_idxs`: a batch_size x max_len tensor\n",
        "                      tag_idxs[i][j] is the index of the j'th tag in the i'th sentence.\n",
        "            `valid_mask`: a batch_size x max_len tensor\n",
        "                        valid_mask[i][j] is True if the i'th sentence has the j'th word.\n",
        "                        Otherwise, valid[i][j] is False.\n",
        "        \"\"\"\n",
        "        words: List[List[str]] = []\n",
        "        tags: List[List[str]] = []\n",
        "        max_len = -1  # length of the longest sentence\n",
        "        for sent in sentences: #For each sentence,append an empty list to words and tags, creating placeholders to store the words and tags of the sentence.\n",
        "            words.append([])\n",
        "            tags.append([])\n",
        "            for w, t in sent:\n",
        "                words[-1].append(w)\n",
        "                tags[-1].append(t)\n",
        "            max_len = max(max_len, len(words[-1]))\n",
        "\n",
        "        batch_size = len(sentences)  #calculate total number of sentences in the current batch.\n",
        "        word_idxs = torch.full(\n",
        "            (batch_size, max_len), fill_value=self.pad_idx, dtype=torch.int64\n",
        "        ) #initialize a tensor word_idxs with dimensions (batch_size, max_len) filled with the padding index self.pad_idx.\n",
        "        tag_idxs = torch.full_like(word_idxs, fill_value=self.tags_vocab[\"O\"]) #tensor filled with the index of the \"O\" tag in the tag vocabulary.\n",
        "        valid_mask = torch.zeros_like(word_idxs, dtype=torch.bool) #will indicate whether a word is valid (True) or padded (False) in each sentence.\n",
        "\n",
        "        ## TODO: Fill in the values in word_idxs, tag_idxs, and valid_mask                      ##################### DONE\n",
        "        ## Caveat: There may be out-of-vocabulary words in validation data\n",
        "        ## See torchtext.vocab.Vocab: https://pytorch.org/text/stable/vocab.html#torchtext.vocab.Vocab\n",
        "\n",
        "        ## START HERE\n",
        "        for i, sent in enumerate(sentences):\n",
        "            for j, (w, t) in enumerate(sent):\n",
        "                word_idxs[i][j] = self.words_vocab[w]  # Assign index of word in vocabulary\n",
        "                tag_idxs[i][j] = self.tags_vocab[t]    # Assign index of tag in vocabulary\n",
        "                valid_mask[i][j] = True                # Mark as valid word\n",
        "        # END\n",
        "\n",
        "        return {\n",
        "            \"words\": words,\n",
        "            \"word_idxs\": word_idxs,\n",
        "            \"tags\": tags,\n",
        "            \"tag_idxs\": tag_idxs,\n",
        "            \"valid_mask\": valid_mask,\n",
        "        }\n",
        "\n",
        "\n",
        "def create_sequence_dataloaders(\n",
        "    batch_size: int, shuffle: bool = True\n",
        ") -> Tuple[DataLoader, DataLoader, Vocab]:\n",
        "    \"\"\"\n",
        "    Create the dataloaders for training and validaiton.\n",
        "    \"\"\"\n",
        "    ds_train = SequenceDataset(\"eng.train\")\n",
        "    ds_val = SequenceDataset(\"eng.val\", words_vocab=ds_train.words_vocab, tags_vocab=ds_train.tags_vocab)\n",
        "    loader_train = DataLoader(\n",
        "        ds_train,\n",
        "        batch_size,\n",
        "        shuffle,\n",
        "        collate_fn=ds_train.form_batch,  # customized function for batching\n",
        "        drop_last=True,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "    loader_val = DataLoader(\n",
        "        ds_val, batch_size, collate_fn=ds_val.form_batch, pin_memory=True\n",
        "    )\n",
        "    return loader_train, loader_val, ds_train #a tuple containing two DataLoader objects for training and validation datasets,and vocabulary object used for the training dataset.\n",
        "#shuffle (whether to shuffle the data during batching)\n",
        "#This creates a PyTorch DataLoader object loader_train for the training dataset.\n",
        "#It takes the training dataset ds_train, batch size batch_size, shuffle flag shuffle, and specifies a custom batching function ds_train.form_batch.\n",
        "#The collate_fn argument specifies how to batch individual data samples together, using the form_batch method of the ds_train object.\n",
        "#drop_last=True ensures that the last incomplete batch is dropped if its size is less than the specified batch size.\n",
        "#pin_memory=True is used to enable faster data transfer to GPU memory if available.\n",
        "#pin_memory=True is used to enable faster data transfer to GPU memory if available.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2EcVxYuYvGv"
      },
      "source": [
        "Here is a simple sanity-check. Try to understand its output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "TazmodGWYx2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecc450ee-dba6-4f29-c5e1-d4c7126b1fae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data from eng.train\n",
            "14041 sentences loaded.\n",
            "Loading data from eng.val\n",
            "3490 sentences loaded.\n",
            "Iterating on the training data..\n",
            "{'words': [['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.'], ['Peter', 'Blackburn'], ['BRUSSELS', '0000-00-00']], 'word_idxs': tensor([[ 2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
            "        [11, 12,  0,  0,  0,  0,  0,  0,  0],\n",
            "        [13, 14,  0,  0,  0,  0,  0,  0,  0]]), 'tags': [['ORG', 'O', 'MISC', 'O', 'O', 'O', 'MISC', 'O', 'O'], ['PER', 'PER'], ['LOC', 'O']], 'tag_idxs': tensor([[0, 1, 2, 1, 1, 1, 2, 1, 1],\n",
            "        [3, 3, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [4, 1, 1, 1, 1, 1, 1, 1, 1]]), 'valid_mask': tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
            "        [ True,  True, False, False, False, False, False, False, False],\n",
            "        [ True,  True, False, False, False, False, False, False, False]])}\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "def check_sequence_dataloader() -> None:\n",
        "    loader_train, _, _ = create_sequence_dataloaders(batch_size=3, shuffle=False)\n",
        "    print(\"Iterating on the training data..\")\n",
        "    for i, data_batch in enumerate(loader_train):\n",
        "        if i == 0:\n",
        "            print(data_batch)\n",
        "    print(\"Done!\")\n",
        "\n",
        "\n",
        "check_sequence_dataloader()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Better Visualization for previous output"
      ],
      "metadata": {
        "id": "ViC-42JMTv5h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tabulate\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5UEkzUmTV-K",
        "outputId": "3a0ec41a-b8d3-470d-8401-0ff7fd788d40"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (0.9.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tabulate import tabulate\n",
        "\n",
        "def visualize_batch(batch_data: Dict[str, Any]) -> None:\n",
        "    \"\"\"\n",
        "    Visualizes the batch data in a table format.\n",
        "    \"\"\"\n",
        "    words = batch_data[\"words\"]\n",
        "    tags = batch_data[\"tags\"]\n",
        "    word_idxs = batch_data[\"word_idxs\"]\n",
        "    tag_idxs = batch_data[\"tag_idxs\"]\n",
        "    valid_mask = batch_data[\"valid_mask\"]\n",
        "\n",
        "    table_data = []\n",
        "    for i in range(len(words)):\n",
        "        table_data.append([\"Sentence \" + str(i + 1), \"\", \"\", \"\", \"\"])\n",
        "        table_data.extend(zip(words[i], tags[i], word_idxs[i], tag_idxs[i], valid_mask[i]))\n",
        "\n",
        "    headers = [\"Word\", \"Tag\", \"Word Index\", \"Tag Index\", \"Valid\"]\n",
        "    print(tabulate(table_data, headers=headers, tablefmt=\"grid\"))\n",
        "\n",
        "\n",
        "def check_sequence_dataloader() -> None:\n",
        "    loader_train, _, _ = create_sequence_dataloaders(batch_size=3, shuffle= False)\n",
        "    print(\"Iterating on the training data..\")\n",
        "    for i, data_batch in enumerate(loader_train):\n",
        "        if i == 0:\n",
        "            visualize_batch(data_batch)\n",
        "    print(\"Done!\")\n",
        "\n",
        "\n",
        "check_sequence_dataloader()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TH4J8JPTYzO",
        "outputId": "d476ec96-7bcc-43bc-a107-a04adb8af081"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data from eng.train\n",
            "14041 sentences loaded.\n",
            "Loading data from eng.val\n",
            "3490 sentences loaded.\n",
            "Iterating on the training data..\n",
            "+------------+-------+--------------+-------------+---------+\n",
            "| Word       | Tag   | Word Index   | Tag Index   | Valid   |\n",
            "+============+=======+==============+=============+=========+\n",
            "| Sentence 1 |       |              |             |         |\n",
            "+------------+-------+--------------+-------------+---------+\n",
            "| EU         | ORG   | 2            | 0           | True    |\n",
            "+------------+-------+--------------+-------------+---------+\n",
            "| rejects    | O     | 3            | 1           | True    |\n",
            "+------------+-------+--------------+-------------+---------+\n",
            "| German     | MISC  | 4            | 2           | True    |\n",
            "+------------+-------+--------------+-------------+---------+\n",
            "| call       | O     | 5            | 1           | True    |\n",
            "+------------+-------+--------------+-------------+---------+\n",
            "| to         | O     | 6            | 1           | True    |\n",
            "+------------+-------+--------------+-------------+---------+\n",
            "| boycott    | O     | 7            | 1           | True    |\n",
            "+------------+-------+--------------+-------------+---------+\n",
            "| British    | MISC  | 8            | 2           | True    |\n",
            "+------------+-------+--------------+-------------+---------+\n",
            "| lamb       | O     | 9            | 1           | True    |\n",
            "+------------+-------+--------------+-------------+---------+\n",
            "| .          | O     | 10           | 1           | True    |\n",
            "+------------+-------+--------------+-------------+---------+\n",
            "| Sentence 2 |       |              |             |         |\n",
            "+------------+-------+--------------+-------------+---------+\n",
            "| Peter      | PER   | 11           | 3           | True    |\n",
            "+------------+-------+--------------+-------------+---------+\n",
            "| Blackburn  | PER   | 12           | 3           | True    |\n",
            "+------------+-------+--------------+-------------+---------+\n",
            "| Sentence 3 |       |              |             |         |\n",
            "+------------+-------+--------------+-------------+---------+\n",
            "| BRUSSELS   | LOC   | 13           | 4           | True    |\n",
            "+------------+-------+--------------+-------------+---------+\n",
            "| 0000-00-00 | O     | 14           | 1           | True    |\n",
            "+------------+-------+--------------+-------------+---------+\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifk3i-obY8YB"
      },
      "source": [
        "### Implement the Model **(8 points)**\n",
        "\n",
        "Next, implement LSTM for predicting NER tags from input words. [nn.LSTM](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html#torch.nn.LSTM) is definitely useful. Further, it is tricky to handle sentences in the same batch with different lengths. Please read the PyTorch documentation in detail!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3V0NvQynZF8e"
      },
      "outputs": [],
      "source": [
        "class LSTM(nn.Module):\n",
        "    \"\"\"\n",
        "    Long short-term memory for NER\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, words_vocab: Vocab, tags_vocab:Vocab, d_emb: int, d_hidden: int, bidirectional: bool) -> None:\n",
        "        \"\"\"\n",
        "        Initialize an LSTM\n",
        "        Parameters:\n",
        "            `words_vocab`: vocabulary of words\n",
        "            `tags_vocab`: vocabulary of tags\n",
        "            `d_emb`: dimension of word embeddings (D)\n",
        "            `d_hidden`: dimension of the hidden layer (H)\n",
        "            `bidirectional`: true if LSTM should be bidirectional\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        # TODO: Create the word embeddings (nn.Embedding),\n",
        "        #       the LSTM (nn.LSTM) and the output layer (nn.Linear).\n",
        "        #       Read the torch docs for additional guidance : https://pytorch.org/docs/stable\n",
        "        #       Note: Pay attention to the LSTM output shapes!\n",
        "        # START HERE\n",
        "        raise NotImplementedError\n",
        "\n",
        "        # END\n",
        "\n",
        "    def forward(\n",
        "        self, word_idxs: torch.Tensor, valid_mask: torch.Tensor\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Given words in sentences, predict the logits of the NER tag.\n",
        "        Parameters:\n",
        "            `word_idxs`: a batch_size x max_len tensor\n",
        "            `valid_mask`: a batch_size x max_len tensor\n",
        "        Return values:\n",
        "            `logits`: a batch_size x max_len x 5 tensor\n",
        "        \"\"\"\n",
        "        # TODO: Implement the forward pass\n",
        "        # START HERE\n",
        "        raise NotImplementedError\n",
        "\n",
        "        # END\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BFTKaB4Zydx"
      },
      "source": [
        "We do a sanity-check by loading a batch of data examples and pass it through the network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PKg1ni4QZ6D1"
      },
      "outputs": [],
      "source": [
        "def check_lstm() -> None:\n",
        "    # Hyperparameters\n",
        "    batch_size = 4\n",
        "    d_emb = 64\n",
        "    d_hidden = 128\n",
        "    bidirectional = True\n",
        "    # Create the dataloaders and the model\n",
        "    loader_train, _, ds_train = create_sequence_dataloaders(batch_size)\n",
        "    model = LSTM(ds_train.words_vocab, ds_train.tags_vocab, d_emb, d_hidden, bidirectional)\n",
        "    device = get_device()\n",
        "    model.to(device)\n",
        "    print(model)\n",
        "    # Get the first batch\n",
        "    data_batch = next(iter(loader_train))\n",
        "    # Move data to GPU\n",
        "    word_idxs = data_batch[\"word_idxs\"].to(device, non_blocking=True)\n",
        "    tag_idxs = data_batch[\"tag_idxs\"].to(device, non_blocking=True)\n",
        "    valid_mask = data_batch[\"valid_mask\"].to(device, non_blocking=True)\n",
        "    # Calculate the model\n",
        "    print(\"Input word_idxs shape:\", word_idxs.size())\n",
        "    print(\"Input valid_mask shape:\", valid_mask.size())\n",
        "    logits = model(word_idxs, valid_mask)\n",
        "    print(\"Output logits shape:\", logits.size())\n",
        "\n",
        "\n",
        "check_lstm()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jddDYUiLY-hc"
      },
      "source": [
        "### Training and Validation **(6 points)**\n",
        "\n",
        "Complete the functions for training and validating the LSTM model. When calculating the loss function, you only want to include values from valid positions (where `valid_mask` is `True`). The `reduction` parameter in [F.cross_entropy](https://pytorch.org/docs/stable/nn.functional.html#torch.nn.functional.cross_entropy) may be useful."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hv_15mnXZ_dy"
      },
      "outputs": [],
      "source": [
        "def train_lstm(\n",
        "    model: nn.Module,\n",
        "    loader: DataLoader,\n",
        "    optimizer: optim.Optimizer,\n",
        "    device: torch.device,\n",
        "    silent: bool = False,  # whether to print the training loss\n",
        ") -> Tuple[float, Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Train the LSTM model.\n",
        "    Return values:\n",
        "        1. the average training loss\n",
        "        2. training metrics such as accuracy and F1 score\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    ground_truth = []\n",
        "    predictions = []\n",
        "    losses = []\n",
        "    report_interval = 100\n",
        "\n",
        "    for i, data_batch in enumerate(loader):\n",
        "        word_idxs = data_batch[\"word_idxs\"].to(device, non_blocking=True)\n",
        "        tag_idxs = data_batch[\"tag_idxs\"].to(device, non_blocking=True)\n",
        "        valid_mask = data_batch[\"valid_mask\"].to(device, non_blocking=True)\n",
        "\n",
        "        # TODO: Do the same tasks as train_ffnn\n",
        "        # START HERE\n",
        "        # Caveat: When calculating the loss, you should only consider positions where valid_mask == True\n",
        "        raise NotImplementedError\n",
        "        # END\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        # we get (unmasked) predictions by getting argmax of logits along last dimension (You will need to define logits!)\n",
        "        net_predictions = torch.argmax(logits, -1)\n",
        "\n",
        "        # flattening a tensor simply converts it from a multi-dimensional to a single-dimensional tensor; we flatten here to make it easier to extract ground truths and predictions\n",
        "        tag_idxs_flat = tag_idxs.flatten()\n",
        "        valid_mask_flat = valid_mask.flatten()\n",
        "        net_predictions_flat = net_predictions.flatten()\n",
        "\n",
        "        ground_truth.extend(tag_idxs_flat[valid_mask_flat].tolist())\n",
        "        predictions.extend(net_predictions_flat[valid_mask_flat].tolist())\n",
        "\n",
        "        if not silent and i > 0 and i % report_interval == 0:\n",
        "            print(\n",
        "                \"\\t[%06d/%06d] Loss: %f\"\n",
        "                % (i, len(loader), np.mean(losses[-report_interval:]))\n",
        "            )\n",
        "\n",
        "    return np.mean(losses), eval_metrics(ground_truth, predictions)\n",
        "\n",
        "\n",
        "def validate_lstm(\n",
        "    model: nn.Module, loader: DataLoader, device: torch.device\n",
        ") -> Tuple[float, Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Validate the model.\n",
        "    Return the validation loss and metrics.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    ground_truth = []\n",
        "    predictions = []\n",
        "    losses = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for data_batch in loader:\n",
        "            word_idxs = data_batch[\"word_idxs\"].to(device, non_blocking=True)\n",
        "            tag_idxs = data_batch[\"tag_idxs\"].to(device, non_blocking=True)\n",
        "            valid_mask = data_batch[\"valid_mask\"].to(device, non_blocking=True)\n",
        "\n",
        "            # TODO: Do the same tasks as validate_ffnn\n",
        "            # START HERE\n",
        "            # Caveat: When calculating the loss, you should only consider positions where valid_mask == True\n",
        "            raise NotImplementedError\n",
        "            # END\n",
        "\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            # we get (unmasked) predictions by getting argmax of logits (You will need to define logits!)\n",
        "            net_predictions = torch.argmax(logits, -1)\n",
        "\n",
        "            # flattening a tensor simply converts it from a multi-dimensional to a single-dimensional tensor; we flatten here to make it easier to extract ground truths and predictions\n",
        "            tag_idxs_flat = tag_idxs.flatten()\n",
        "            valid_mask_flat = valid_mask.flatten()\n",
        "            net_predictions_flat = net_predictions.flatten()\n",
        "\n",
        "            ground_truth.extend(tag_idxs_flat[valid_mask_flat].tolist())\n",
        "            predictions.extend(net_predictions_flat[valid_mask_flat].tolist())\n",
        "\n",
        "    return np.mean(losses), eval_metrics(ground_truth, predictions)\n",
        "\n",
        "\n",
        "def train_val_loop_lstm(hyperparams: Dict[str, Any]) -> None:\n",
        "    \"\"\"\n",
        "    Train and validate the LSTM model for a number of epochs.\n",
        "    \"\"\"\n",
        "    print(\"Hyperparameters:\", hyperparams)\n",
        "    # Create the dataloaders\n",
        "    loader_train, loader_val, ds_train = create_sequence_dataloaders(\n",
        "        hyperparams[\"batch_size\"]\n",
        "    )\n",
        "    # Create the model\n",
        "    model = LSTM(\n",
        "        ds_train.words_vocab,\n",
        "        ds_train.tags_vocab,\n",
        "        hyperparams[\"d_emb\"],\n",
        "        hyperparams[\"d_hidden\"],\n",
        "        hyperparams[\"bidirectional\"],\n",
        "    )\n",
        "    device = get_device()\n",
        "    model.to(device)\n",
        "    print(model)\n",
        "    # Create the optimizer\n",
        "    optimizer = optim.RMSprop(\n",
        "        model.parameters(), hyperparams[\"learning_rate\"], weight_decay=hyperparams[\"l2\"]\n",
        "    )\n",
        "\n",
        "    # Train and validate\n",
        "    for i in range(hyperparams[\"num_epochs\"]):\n",
        "        print(\"Epoch #%d\" % i)\n",
        "\n",
        "        print(\"Training..\")\n",
        "        loss_train, metrics_train = train_lstm(model, loader_train, optimizer, device)\n",
        "        print(\"Training loss: \", loss_train)\n",
        "        print(\"Training metrics:\")\n",
        "        for k, v in metrics_train.items():\n",
        "            print(\"\\t\", k, \": \", v)\n",
        "\n",
        "        print(\"Validating..\")\n",
        "        loss_val, metrics_val = validate_lstm(model, loader_val, device)\n",
        "        print(\"Validation loss: \", loss_val)\n",
        "        print(\"Validation metrics:\")\n",
        "        for k, v in metrics_val.items():\n",
        "            print(\"\\t\", k, \": \", v)\n",
        "\n",
        "    print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rU9Nef7yal_M"
      },
      "source": [
        "Run the experiment:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFxQxlokai6Z"
      },
      "outputs": [],
      "source": [
        "train_val_loop_lstm({\n",
        "    \"bidirectional\": True,\n",
        "    \"batch_size\": 512,\n",
        "    \"d_emb\": 64,\n",
        "    \"d_hidden\": 128,\n",
        "    \"num_epochs\": 15,\n",
        "    \"learning_rate\": 0.005,\n",
        "    \"l2\": 1e-6,\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vA-Yjqg7n0V"
      },
      "source": [
        "We were using bidirectional LSTMs. Please re-run the experiment with a regular (unidirectional) LSTM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wNrdvJ98ARB"
      },
      "outputs": [],
      "source": [
        "## TODO: Re-run with unidirectional LSTMs\n",
        "## Keep other hyperparameters fixed\n",
        "train_val_loop_lstm({\n",
        "    \"bidirectional\": False,\n",
        "    \"batch_size\": 512,\n",
        "    \"d_emb\": 64,\n",
        "    \"d_hidden\": 128,\n",
        "    \"num_epochs\": 15,\n",
        "    \"learning_rate\": 0.005,\n",
        "    \"l2\": 1e-6,\n",
        "})\n",
        "## END"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8UChDyKaPBs"
      },
      "source": [
        "### Questions **(2 points)**\n",
        "\n",
        "(a) How does the final performance of LSTMs compare to FFNNs? Is it better? What is a possible explanation?\n",
        "\n",
        "**TODO: Please fill in your answer here**\n",
        "\n",
        "(b) How does bidirectional LSTMs compare to unidirectional LSTMs? Why?\n",
        "\n",
        "**TODO: Please fill in your answer here**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kMEWxkN_bpIT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}