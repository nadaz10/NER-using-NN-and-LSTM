{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nadaz10/NER-using-NN-and-LSTM/blob/main/Named_Entity_Recognition_FFNNs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6czvz5VKO5M"
      },
      "source": [
        "# Notebook for Programming in Problem 3\n",
        "Welcome to the programming portion of the assignment! Each assignment throughout the semester will have a written portion and a programming portion. We will be using [Google Colab](https://colab.research.google.com/notebooks/intro.ipynb#recent=true), so if you have never used it before, take a quick look through this introduction: [Working with Google Colab](https://docs.google.com/document/d/1LlnXoOblXwW3YX-0yG_5seTXJsb3kRdMMRYqs8Qqum4/edit?usp=sharing).\n",
        "\n",
        "We'll also be programming in Python, which we will assume a basic familiarity with. Python has fantastic community support and we'll be using numerous packages for machine learning (ML) and natural language processing (NLP) tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5o8HI5JqTvU5"
      },
      "source": [
        "## Learning Objectives\n",
        "In this problem, we will use [PyTorch](https://pytorch.org/) to implement feedforward neural networks (FFNNs) and long short-term memory (LSTM) for named entity recognition (NER). We will use the same dataset as in Assignment #2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObrHyvWvTyGZ"
      },
      "source": [
        "## Writing Code\n",
        "Look for the keyword \"TODO\" and fill in your code in the empty space.\n",
        "Feel free to change function signatures, but be careful that you might need to also change how they are called in other parts of the notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GAWytObKh4K"
      },
      "source": [
        "## Use GPUs in Colab\n",
        "\n",
        "GPUs are not strictly necessary for this assignment, but they will accerlerate your experiments and may be helpful for your final project. To enable the free GPU provided by Colab, just go to **Edit > Notebook settings** and select **GPU** as **Hardware accelerator**. To test your GPU, run the `nvidia-smi` command."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "r6YTnpgbFdMI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b88e910-a9a7-4e23-85da-07a4bcec0536"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Apr 27 11:55:18 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbgSdkFMMa3E"
      },
      "source": [
        "You should see a table summarizing the current status of the GPU, including the model, power consumption, GPU memory usage, etc. However, Colab does not guarantee which model you will get. We tested the assignment successfully on Tesla T4 but had some problems on other GPUs. **Please make sure you get a Tesla T4** by checking the output of `nvidia-smi`. We empirically observe that you are more likely to get a T4 **with your Princeton account**.\n",
        "\n",
        "If you are still unable to get a T4. You have 3 options:\n",
        "1. Reload the page until you get one.\n",
        "2. Proceed with other GPUs. They should work as long as Colab does not crash when executing code.\n",
        "3. Disable the GPU and use the CPU for this assignment, which is totally fine."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26HdExpsKTOg"
      },
      "source": [
        "## Learning PyTorch\n",
        "\n",
        "This assignment assumes basic familiarity with [PyTorch](https://pytorch.org/), which is a much needed skill for the upcoming Assignment #4, for the final project, and even beyond this course. If you aren't familiar with PyTorch, don't worry, it's a great time to start now! Here are some resources to help you get started. You may also find plenty of them online.\n",
        "\n",
        "* We will cover PyTorch in the precept on 3/18. Watch the video on Canvas if you are not able to make it.\n",
        "* [Deep Learning with PyTorch: A 60 Minute Blitz](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)\n",
        "* [Learning PyTorch with Examples](https://pytorch.org/tutorials/beginner/pytorch_with_examples.html)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnYMKJlKNXYe"
      },
      "source": [
        "## Installing PyTorch and Other Packages\n",
        "\n",
        "Install PyTorch using pip. See [https://pytorch.org/](https://pytorch.org/) if you want to install it on your computer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-dRVuiP_JVdT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac9c2548-6309-4b7d-ff98-7ab959f16e9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext) (4.66.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.31.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext) (1.25.2)\n",
            "Requirement already satisfied: torchdata==0.7.1 in /usr/local/lib/python3.10/dist-packages (from torchtext) (0.7.1)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.7.1->torchtext) (2.0.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchtext -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPsFH637OpLy"
      },
      "source": [
        "Test if our installation works:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "c62StNb2NvKk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67bb7fe5-35d9-45ce-ea20-be46a971103e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch successfully installed!\n",
            "Version: 2.2.1+cu121\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Multiply two matrices on GPU\n",
        "a = torch.rand(100, 200).cuda()\n",
        "b = torch.rand(200, 100).cuda()\n",
        "c = torch.matmul(a, b)\n",
        "\n",
        "print(\"PyTorch successfully installed!\")\n",
        "print(\"Version:\", torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qaC8sxcqkGX"
      },
      "source": [
        "Also install [scikit-learn](https://scikit-learn.org/stable/). We will use it for calculating evaluation metrics such as accuracy and F1 score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5Y2xB_uqqM9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd8eb7d2-7b2e-49ea-ed77-0fb1e9ac3c32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.4.1.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.3.0)\n",
            "Installing collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "Successfully installed scikit-learn-1.4.1.post1\n"
          ]
        }
      ],
      "source": [
        "!pip install -U scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhV4CYivRbt4"
      },
      "source": [
        "Let's import all the packages at once:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "EjRM4cCFRh-d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchtext.vocab import Vocab, vocab\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "import re\n",
        "from collections import Counter\n",
        "from typing import List, Tuple, Dict, Optional, Any"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yn1bIPjAN-9V"
      },
      "source": [
        "## Feedforward Neural Network (FFNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJOKIneRTrTH"
      },
      "source": [
        "### Data Loading\n",
        "\n",
        "We will use the same dataset for named entity recognition in Assignment #2. First download the data and take a look at the first 50 lines:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lWqz7kDxSqeb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "529ef05c-4f4a-40cf-80d0-d54463e52275"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EU NNP I-NP ORG\n",
            "rejects VBZ I-VP O\n",
            "German JJ I-NP MISC\n",
            "call NN I-NP O\n",
            "to TO I-VP O\n",
            "boycott VB I-VP O\n",
            "British JJ I-NP MISC\n",
            "lamb NN I-NP O\n",
            ". . O O\n",
            "\n",
            "Peter NNP I-NP PER\n",
            "Blackburn NNP I-NP PER\n",
            "\n",
            "BRUSSELS NNP I-NP LOC\n",
            "1996-08-22 CD I-NP O\n",
            "\n",
            "The DT I-NP O\n",
            "European NNP I-NP ORG\n",
            "Commission NNP I-NP ORG\n",
            "said VBD I-VP O\n",
            "on IN I-PP O\n",
            "Thursday NNP I-NP O\n",
            "it PRP B-NP O\n",
            "disagreed VBD I-VP O\n",
            "with IN I-PP O\n",
            "German JJ I-NP MISC\n",
            "advice NN I-NP O\n",
            "to TO I-PP O\n",
            "consumers NNS I-NP O\n",
            "to TO I-VP O\n",
            "shun VB I-VP O\n",
            "British JJ I-NP MISC\n",
            "lamb NN I-NP O\n",
            "until IN I-SBAR O\n",
            "scientists NNS I-NP O\n",
            "determine VBP I-VP O\n",
            "whether IN I-SBAR O\n",
            "mad JJ I-NP O\n",
            "cow NN I-NP O\n",
            "disease NN I-NP O\n",
            "can MD I-VP O\n",
            "be VB I-VP O\n",
            "transmitted VBN I-VP O\n",
            "to TO I-PP O\n",
            "sheep NN I-NP O\n",
            ". . O O\n",
            "\n",
            "Germany NNP I-NP LOC\n",
            "'s POS B-NP O\n",
            "representative NN I-NP O\n"
          ]
        }
      ],
      "source": [
        "!wget --quiet https://princeton-nlp.github.io/cos484/assignments/a2/eng.train\n",
        "!wget --quiet https://princeton-nlp.github.io/cos484/assignments/a2/eng.val\n",
        "!cat eng.train | head -n 50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVt1a6nzWsiF"
      },
      "source": [
        "Each line corresponds to a word. Different sentences are separated by an additional line break. Take \"EU NNP I-NP ORG\" as an example. \"EU\" is a word. \"NNP\" and \"I-NP\" are tags for POS tagging and chunking, which we will ignore. \"ORG\" is the tag for NER, which is our prediction target. There are 5 possible values for the NER tag: ORG, PER, LOC, MISC, and O.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooQEJEafWCcd"
      },
      "source": [
        "First, we write a dataloader for loading the dataset into mini-batches used for training the model. See [torch.utils.data](https://pytorch.org/docs/stable/data.html) for how dataloaders work in PyTorch. In short, we typically need to do two things:\n",
        "1. Define a [map-style dataset](https://pytorch.org/docs/stable/data.html#map-style-datasets) by subclassing [Dataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) and overriding 3 methods: `__init__`, `__getitem__`, and `__len__`.\n",
        "1. Create a [Dataloader](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) by calling its constructor. We have to specify the dataset and a few hyperparameters such as batch size.\n",
        "\n",
        "Most of the work has been done by us. As a simple exercise, try to understand the code and implement `__len__`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WnNfOBUYJvVW"
      },
      "outputs": [],
      "source": [
        "# A sentence is a list of (word, tag) tuples.\n",
        "# For example, [(\"hello\", \"O\"), (\"world\", \"O\"), (\"!\", \"O\")]\n",
        "Sentence = List[Tuple[str, str]]\n",
        "\n",
        "\n",
        "def read_data_file(\n",
        "    datapath: str,\n",
        ") -> Tuple[List[Sentence], Dict[str, int], Dict[str, int]]:\n",
        "    \"\"\"\n",
        "    Read and preprocess input data from the file `datapath`.\n",
        "    Example:\n",
        "    ```\n",
        "        sentences, word_cnt, tag_cnt = read_data_file(\"eng.train\")\n",
        "    ```\n",
        "    Return values:\n",
        "        `sentences`: a list of sentences, including words and NER tags\n",
        "        `word_cnt`: a Counter object, the number of occurrences of each word\n",
        "        `tag_cnt`: a Counter object, the number of occurences of each NER tag\n",
        "    \"\"\"\n",
        "    sentences: List[Sentence] = []\n",
        "    word_cnt: Dict[str, int] = Counter()\n",
        "    tag_cnt: Dict[str, int] = Counter()\n",
        "\n",
        "    for sentence_txt in open(datapath).read().split(\"\\n\\n\"):\n",
        "        if \"DOCSTART\" in sentence_txt:\n",
        "            # Ignore dummy sentences at the begining of each document.\n",
        "            continue\n",
        "        # Read a new sentence\n",
        "        sentences.append([])\n",
        "        for token in sentence_txt.split(\"\\n\"):\n",
        "            w, _, _, t = token.split()\n",
        "            # Replace all digits with \"0\" to reduce out-of-vocabulary words\n",
        "            w = re.sub(\"\\d\", \"0\", w)\n",
        "            word_cnt[w] += 1\n",
        "            tag_cnt[t] += 1\n",
        "            sentences[-1].append((w, t))\n",
        "\n",
        "    return sentences, word_cnt, tag_cnt\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFVnIjA8KEe0"
      },
      "source": [
        "## Implement the `__len__` function below **(1 point)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "9RGv1K0pP1bR"
      },
      "outputs": [],
      "source": [
        "\n",
        "class FixedWindowDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Each data example is a word, its NER tag (the target), and a fixed window centered around it (the input).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        datapath: str,\n",
        "        window_size: int,\n",
        "        words_vocab: Optional[Vocab] = None,\n",
        "        tags_vocab: Optional[Vocab] = None,\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Initialize the dataset by reading from datapath.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.examples = []\n",
        "        START = \"<START>\"\n",
        "        END = \"<END>\"\n",
        "        UNKNOWN = \"<UNKNOWN>\"\n",
        "\n",
        "        print(\"Loading data from %s\" % datapath)\n",
        "        sentences, word_cnt, tag_cnt = read_data_file(datapath)\n",
        "\n",
        "        # Extract windows\n",
        "        for sent in sentences:\n",
        "            words = [START for _ in range(window_size)]\n",
        "            tags = [None for _ in range(window_size)]\n",
        "            for w, t in sent:\n",
        "                words.append(w)\n",
        "                tags.append(t)\n",
        "            words.extend([END for _ in range(window_size)])\n",
        "            tags.extend([None for _ in range(window_size)])\n",
        "\n",
        "            for i, t in enumerate(tags[window_size:-window_size], start=window_size):\n",
        "                self.examples.append(\n",
        "                    {\n",
        "                        \"word\": words[i],\n",
        "                        \"tag\": t,\n",
        "                        \"context\": words[i - window_size : i + window_size + 1],\n",
        "                    }\n",
        "                )\n",
        "\n",
        "        print(\"%d examples loaded.\" % len(self.examples))\n",
        "\n",
        "        # set vocabs\n",
        "        if words_vocab is None:\n",
        "            words_vocab = vocab(word_cnt, specials=[START, END, UNKNOWN]) # automatically create a vocabulary from words in dataset\n",
        "            words_vocab.set_default_index(words_vocab[UNKNOWN])\n",
        "        self.words_vocab = words_vocab\n",
        "        self.unknown_idx = self.words_vocab[UNKNOWN]\n",
        "        self.start_idx = self.words_vocab[START]\n",
        "        self.end_idx = self.words_vocab[END]\n",
        "\n",
        "        if tags_vocab is None:\n",
        "            tags_vocab = vocab(tag_cnt, specials=[]) # automatically create tags vocabulary from tags in dataset\n",
        "        self.tags_vocab = tags_vocab\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Get the idx'th example in the dataset.\n",
        "        Convert words and the tag to indexes.\n",
        "        \"\"\"\n",
        "        example = self.examples[idx]\n",
        "        word = example[\"word\"]\n",
        "        tag = example[\"tag\"]\n",
        "        context = example[\"context\"]\n",
        "        return {\n",
        "            \"word\": word,\n",
        "            \"word_idx\": self.words_vocab[word],\n",
        "            \"tag\": tag,\n",
        "            \"tag_idx\": self.tags_vocab[tag],\n",
        "            \"context\": context,\n",
        "            \"context_idxs\": torch.tensor(\n",
        "                [self.words_vocab[w] for w in context]\n",
        "            ),\n",
        "        }\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "         return len(self.examples)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "F-aHcN5yJyoa"
      },
      "outputs": [],
      "source": [
        "def create_fixed_window_dataloaders(\n",
        "    batch_size: int, window_size: int, shuffle: bool = True\n",
        ") -> Tuple[DataLoader, DataLoader, Dict[str, Vocab]]:\n",
        "    \"\"\"\n",
        "    Create the dataloaders for training and validaiton.\n",
        "    \"\"\"\n",
        "    ds_train = FixedWindowDataset(\"eng.train\", window_size)\n",
        "    # Re-use the vocabulary of the training data\n",
        "    ds_val = FixedWindowDataset(\"eng.val\", window_size, words_vocab=ds_train.words_vocab, tags_vocab=ds_train.tags_vocab)\n",
        "    loader_train = DataLoader(\n",
        "        ds_train, batch_size, shuffle, drop_last=True, pin_memory=True\n",
        "    )\n",
        "    loader_val = DataLoader(ds_val, batch_size, pin_memory=True)\n",
        "    return loader_train, loader_val, ds_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODfPyQjPSmCv"
      },
      "source": [
        "Let's test our dataloader. Try to understand the output, as it will save your time later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Zmt9c9svgzy8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecb3e3f5-9814-4fe7-c0e1-aa966f1ad09d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data from eng.train\n",
            "203621 examples loaded.\n",
            "Loading data from eng.val\n",
            "49086 examples loaded.\n",
            "Iterating on the training data..\n",
            "{'word': ['EU', 'rejects', 'German'], 'word_idx': tensor([3, 4, 5]), 'tag': ['ORG', 'O', 'MISC'], 'tag_idx': tensor([0, 1, 2]), 'context': [['<START>', '<START>', 'EU'], ['<START>', 'EU', 'rejects'], ['EU', 'rejects', 'German'], ['rejects', 'German', 'call'], ['German', 'call', 'to']], 'context_idxs': tensor([[0, 0, 3, 4, 5],\n",
            "        [0, 3, 4, 5, 6],\n",
            "        [3, 4, 5, 6, 7]])}\n",
            "5\n",
            "torch.Size([3, 5])\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "def check_fixed_window_dataloader() -> None:\n",
        "    loader_train, _, _ = create_fixed_window_dataloaders(\n",
        "        batch_size=3, window_size=2, shuffle=False\n",
        "    )\n",
        "    print(\"Iterating on the training data..\")\n",
        "    for i, data_batch in enumerate(loader_train):\n",
        "        if i == 0:\n",
        "            print(data_batch)\n",
        "            print(len(data_batch[\"context\"]))\n",
        "            print(data_batch[\"context_idxs\"].shape)\n",
        "    print(\"Done!\")\n",
        "\n",
        "\n",
        "check_fixed_window_dataloader()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hR_aJ-FincuN"
      },
      "source": [
        "### Implement the Model **(4 points)**   \n",
        "\n",
        "Next, let's implement feedforward neural networks following the description of Problem 1 in Assignment #3.\n",
        "\n",
        "Models in PyTorch are subclasses of [torch.nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module). You have to override `__init__` for initializing the model and `forward` for calculating the forward pass. Checkout this [tutorial](https://pytorch.org/tutorials/beginner/nn_tutorial.html#) if you are not sure how torch.nn.Module works.\n",
        "\n",
        "PyTorch provides a wide array of [neural network layers](https://pytorch.org/docs/stable/nn.html) as building blocks for your model. Here are some of them that may be relevant:\n",
        "* [nn.Embedding](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding)\n",
        "* [nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear)\n",
        "* [torch.sigmoid](https://pytorch.org/docs/stable/generated/torch.sigmoid.html#torch.sigmoid) or [nn.Sigmoid](https://pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html#torch.nn.Sigmoid)\n",
        "\n",
        "Note a difference with Problem 3 of Assignment #2 is that we do not apply softmax when calculatinng $\\hat{y}^{(t)}$. Instead, we leave what softmax does to the loss function [F.cross_entropy](https://pytorch.org/docs/stable/nn.functional.html#torch.nn.functional.cross_entropy). For details, please see its difference with [F.nll_loss](https://pytorch.org/docs/stable/nn.functional.html#torch.nn.functional.nll_loss)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Hx0oMgVffSD1"
      },
      "outputs": [],
      "source": [
        "class FFNN(nn.Module):\n",
        "    \"\"\"\n",
        "    Feedforward Neural Networks for NER\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, words_vocab: Vocab, tags_vocab: Vocab, window_size: int, d_emb: int, d_hidden: int\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Initialize a two-layer feedforward neural network with sigmoid activation.\n",
        "        Parameters:\n",
        "            `words_vocab`: vocabulary of words\n",
        "            `tags_vocab`: vocabulary of tags\n",
        "            `window_size`: size of the context window (w in Problem 3 of Assignment #2)\n",
        "            `d_emb`: dimension of word embeddings (D in Problem 3 of Assignment #2)\n",
        "            `d_hidden`: dimension of the hidden layer (H in Problem 3 of Assignment #2)\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.words_vocab_size = len(words_vocab)\n",
        "        self.tags_vocab_size = len(tags_vocab)\n",
        "        self.embedding = nn.Embedding(self.words_vocab_size, d_emb)\n",
        "        self.hidden_layer = nn.Linear((2 * window_size + 1) * d_emb, d_hidden)\n",
        "        self.output_layer = nn.Linear(d_hidden, self.tags_vocab_size)\n",
        "\n",
        "    def forward(self, context_idxs: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Given the word indexes in a context window, predict the logits of the NER tag.\n",
        "        Parameters:\n",
        "            `context_idxs`: a batch_size x (2 * window_size + 1) tensor\n",
        "                          context_idxs[i] contains word indexes in the window of the i'th data example.\n",
        "        Return values:\n",
        "            `logits`: a batch_size x 5 tensor (\\hat{y}^{(t)} in Problem 3 of Assignment #2, without softmax)\n",
        "                    logits[i][j] is the output score (before softmax) of the i'th example for tag j.\n",
        "        \"\"\"\n",
        "        batch_size = context_idxs.size(0)\n",
        "        embedded = self.embedding(context_idxs)  # Shape: batch_size x (2 * window_size + 1) x d_emb\n",
        "        embedded_flat = embedded.view(batch_size, -1)  # Shape: batch_size x ((2 * window_size + 1) * d_emb)\n",
        "        hidden = F.sigmoid(self.hidden_layer(embedded_flat))  # Shape: batch_size x d_hidden\n",
        "        logits = self.output_layer(hidden)  # Shape: batch_size x tags_vocab_size\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyZCvfOMR7YP"
      },
      "source": [
        "Optionally, let's do a simple sanity check of your implementation. In `check_ffnn`, we load a batch of data examples and pass it through the FFNN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "WLMGYSZ7KxzP"
      },
      "outputs": [],
      "source": [
        "# Some helper code\n",
        "def get_device() -> torch.device:\n",
        "    \"\"\"\n",
        "    Use GPU when it is available; use CPU otherwise.\n",
        "    See https://pytorch.org/docs/stable/notes/cuda.html#device-agnostic-code\n",
        "    \"\"\"\n",
        "    return torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "H7jikP_1fZP-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6aa2c14d-552c-4078-c3e2-a5bfb2cb69dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data from eng.train\n",
            "203621 examples loaded.\n",
            "Loading data from eng.val\n",
            "49086 examples loaded.\n",
            "FFNN(\n",
            "  (embedding): Embedding(20103, 64)\n",
            "  (hidden_layer): Linear(in_features=448, out_features=128, bias=True)\n",
            "  (output_layer): Linear(in_features=128, out_features=5, bias=True)\n",
            ")\n",
            "Input tensor shape: torch.Size([3, 7])\n",
            "Output tensor shape: torch.Size([3, 5])\n"
          ]
        }
      ],
      "source": [
        "def check_ffnn() -> None:\n",
        "  # Hyperparameters\n",
        "  batch_size = 3\n",
        "  d_emb = 64\n",
        "  d_hidden = 128\n",
        "  window_size = 3\n",
        "  # Create the dataloaders and the model\n",
        "  loader_train, _, ds_train = create_fixed_window_dataloaders(batch_size, window_size)\n",
        "  model = FFNN(ds_train.words_vocab, ds_train.tags_vocab, window_size, d_emb, d_hidden)\n",
        "  device = get_device()\n",
        "  model.to(device)\n",
        "  print(model)\n",
        "  # Get the first batch\n",
        "  data_batch = next(iter(loader_train))\n",
        "  # Move data to GPU\n",
        "  context_idxs = data_batch[\"context_idxs\"].to(device, non_blocking=True)\n",
        "  tag_idx = data_batch[\"tag_idx\"].to(device, non_blocking=True)\n",
        "  # Calculate the model\n",
        "  print(\"Input tensor shape:\", context_idxs.size())\n",
        "  logits = model(context_idxs)\n",
        "  print(\"Output tensor shape:\", logits.size())\n",
        "\n",
        "check_ffnn()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "PkRIOgeXIng0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93b0da36-5bd1-49e2-bfb1-3dca0d555c73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data from eng.train\n",
            "203621 examples loaded.\n"
          ]
        }
      ],
      "source": [
        "ds_train = FixedWindowDataset(\"eng.train\", 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0angAnEno9v"
      },
      "source": [
        "### Training and Validation  **(4 points)**   \n",
        "\n",
        "Having implemented the model, the next step is to implement functions for training and validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "vWcKwiIMjekY"
      },
      "outputs": [],
      "source": [
        "def eval_metrics(ground_truth: List[int], predictions: List[int]) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Calculate various evaluation metrics such as accuracy and F1 score\n",
        "    Parameters:\n",
        "        `ground_truth`: the list of ground truth NER tags\n",
        "        `predictions`: the list of predicted NER tags\n",
        "    \"\"\"\n",
        "    f1_scores = f1_score(ground_truth, predictions, average=None)\n",
        "    return {\n",
        "        \"accuracy\": accuracy_score(ground_truth, predictions),\n",
        "        \"f1\": f1_scores,\n",
        "        \"average f1\": np.mean(f1_scores),\n",
        "        \"confusion matrix\": confusion_matrix(ground_truth, predictions),\n",
        "    }\n",
        "\n",
        "\n",
        "def train_ffnn(\n",
        "    model: nn.Module,\n",
        "    loader: DataLoader,\n",
        "    optimizer: optim.Optimizer,\n",
        "    device: torch.device,\n",
        "    silent: bool = False,  # whether to print the training loss\n",
        ") -> Tuple[float, Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Train the FFNN model.\n",
        "    Return values:\n",
        "        1. the average training loss\n",
        "        2. training metrics such as accuracy and F1 score\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    ground_truth = []\n",
        "    predictions = []\n",
        "    losses = []\n",
        "    report_interval = 100\n",
        "\n",
        "    for i, data_batch in enumerate(loader):\n",
        "        context_idxs = data_batch[\"context_idxs\"].to(device, non_blocking=True)\n",
        "        tag_idx = data_batch[\"tag_idx\"].to(device, non_blocking=True)\n",
        "\n",
        "        logits = model(context_idxs)\n",
        "\n",
        "        # Calculate the loss using the output and the ground truth tags\n",
        "        loss = F.cross_entropy(logits, tag_idx)\n",
        "\n",
        "        # Perform the backward pass to calculate the gradient\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        # Use the optimizer to update model parameters\n",
        "        optimizer.step()\n",
        "        losses.append(loss.item())\n",
        "        ground_truth.extend(tag_idx.tolist())\n",
        "        predictions.extend(logits.argmax(dim=-1).tolist())\n",
        "\n",
        "        if not silent and i > 0 and i % report_interval == 0:\n",
        "            print(\n",
        "                \"\\t[%06d/%06d] Loss: %f\"\n",
        "                % (i, len(loader), np.mean(losses[-report_interval:]))\n",
        "            )\n",
        "\n",
        "    return np.mean(losses), eval_metrics(ground_truth, predictions)\n",
        "\n",
        "\n",
        "def validate_ffnn(\n",
        "    model: nn.Module, loader: DataLoader, device: torch.device\n",
        ") -> Tuple[float, Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Validate the FFNN model.\n",
        "    Return values:\n",
        "        1. the average validation loss\n",
        "        2. validation metrics such as accuracy and F1 score\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    ground_truth = []\n",
        "    predictions = []\n",
        "    losses = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for data_batch in loader:\n",
        "            context_idxs = data_batch[\"context_idxs\"].to(device, non_blocking=True)\n",
        "            tag_idx = data_batch[\"tag_idx\"].to(device, non_blocking=True)\n",
        "\n",
        "\n",
        "            # Perform the forward pass to calculate the model's output\n",
        "            logits = model(context_idxs)\n",
        "\n",
        "            # Calculate the loss using the output and the ground truth tags\n",
        "            loss = F.cross_entropy(logits, tag_idx)\n",
        "\n",
        "\n",
        "            losses.append(loss.item())\n",
        "            ground_truth.extend(tag_idx.tolist())\n",
        "            predictions.extend(logits.argmax(dim=-1).tolist())\n",
        "\n",
        "    return np.mean(losses), eval_metrics(ground_truth, predictions)\n",
        "\n",
        "\n",
        "def train_val_loop_ffnn(hyperparams: Dict[str, Any]) -> None:\n",
        "    \"\"\"\n",
        "    Train and validate the FFNN model for a number of epochs.\n",
        "    \"\"\"\n",
        "    print(\"Hyperparameters:\", hyperparams)\n",
        "    # Create the dataloaders\n",
        "    loader_train, loader_val, ds_train = create_fixed_window_dataloaders(\n",
        "        hyperparams[\"batch_size\"], hyperparams[\"window_size\"]\n",
        "    )\n",
        "    # Create the model\n",
        "    model = FFNN(\n",
        "        ds_train.words_vocab,\n",
        "        ds_train.tags_vocab,\n",
        "        hyperparams[\"window_size\"],\n",
        "        hyperparams[\"d_emb\"],\n",
        "        hyperparams[\"d_hidden\"],\n",
        "    )\n",
        "    device = get_device()\n",
        "    model.to(device)\n",
        "    print(model)\n",
        "    # Create the optimizer\n",
        "    optimizer = optim.RMSprop(\n",
        "        model.parameters(), hyperparams[\"learning_rate\"], weight_decay=hyperparams[\"l2\"]\n",
        "    )\n",
        "\n",
        "    # Train and validate\n",
        "    for i in range(hyperparams[\"num_epochs\"]):\n",
        "        print(\"Epoch #%d\" % i)\n",
        "\n",
        "        print(\"Training..\")\n",
        "        loss_train, metrics_train = train_ffnn(\n",
        "            model, loader_train, optimizer, device, silent=True\n",
        "        )\n",
        "        print(\"Training loss: \", loss_train)\n",
        "        print(\"Training metrics:\")\n",
        "        for k, v in metrics_train.items():\n",
        "            print(\"\\t\", k, \": \", v)\n",
        "\n",
        "        print(\"Validating..\")\n",
        "        loss_val, metrics_val = validate_ffnn(model, loader_val, device)\n",
        "        print(\"Validation loss: \", loss_val)\n",
        "        print(\"Validation metrics:\")\n",
        "        for k, v in metrics_val.items():\n",
        "            print(\"\\t\", k, \": \", v)\n",
        "\n",
        "    print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbuC7sYHX3Wl"
      },
      "source": [
        "We are ready to run experiments! Let's train the model for 5 epochs, with `window_size=2`. After each epoch, we perform validation and print the evaluation metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "5ZTOFj9NXl65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81707eb3-272f-488c-e557-5cb8f65cd75f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hyperparameters: {'batch_size': 512, 'd_emb': 64, 'd_hidden': 128, 'window_size': 2, 'num_epochs': 5, 'learning_rate': 0.01, 'l2': 1e-06}\n",
            "Loading data from eng.train\n",
            "203621 examples loaded.\n",
            "Loading data from eng.val\n",
            "49086 examples loaded.\n",
            "FFNN(\n",
            "  (embedding): Embedding(20103, 64)\n",
            "  (hidden_layer): Linear(in_features=320, out_features=128, bias=True)\n",
            "  (output_layer): Linear(in_features=128, out_features=5, bias=True)\n",
            ")\n",
            "Epoch #0\n",
            "Training..\n",
            "Training loss:  0.18229561023207697\n",
            "Training metrics:\n",
            "\t accuracy :  0.9464440333753149\n",
            "\t f1 :  [0.73899321 0.97677269 0.70174111 0.83770606 0.80387904]\n",
            "\t average f1 :  0.8118184187931332\n",
            "\t confusion matrix :  [[  6907   2007    210    423    457]\n",
            " [   871 167370    172    571    289]\n",
            " [   251   1194   2781    181    181]\n",
            " [   296   1565     71   9020    165]\n",
            " [   364   1291    104    223   6300]]\n",
            "Validating..\n",
            "Validation loss:  0.13047502368378142\n",
            "Validation metrics:\n",
            "\t accuracy :  0.9619647149900176\n",
            "\t f1 :  [0.80456621 0.98368735 0.77495953 0.86803874 0.88145416]\n",
            "\t average f1 :  0.8625411986663304\n",
            "\t confusion matrix :  [[ 1762   327    44    40    77]\n",
            " [  120 40915    55    46    28]\n",
            " [   37   215   718    13    24]\n",
            " [  109   401    10  2151    19]\n",
            " [  102   165    19    16  1673]]\n",
            "Epoch #1\n",
            "Training..\n",
            "Training loss:  0.034994314490378806\n",
            "Training metrics:\n",
            "\t accuracy :  0.9900228274559194\n",
            "\t f1 :  [0.94209309 0.99678347 0.92391546 0.98096738 0.95726806]\n",
            "\t average f1 :  0.9602054912304302\n",
            "\t confusion matrix :  [[  9371    299    103     64    174]\n",
            " [   197 168892     74     56     56]\n",
            " [   103    213   4153     48     67]\n",
            " [    58     87     19  10901     45]\n",
            " [   154    108     57     46   7919]]\n",
            "Validating..\n",
            "Validation loss:  0.15989370965204822\n",
            "Validation metrics:\n",
            "\t accuracy :  0.9613127979464613\n",
            "\t f1 :  [0.78096871 0.98432451 0.80921053 0.85573569 0.89037916]\n",
            "\t average f1 :  0.8641237177070948\n",
            "\t confusion matrix :  [[ 1822   278    29    37    84]\n",
            " [  231 40816    36    39    42]\n",
            " [   47   191   738     9    22]\n",
            " [  226   345     6  2085    28]\n",
            " [   90   138     8    13  1726]]\n",
            "Epoch #2\n",
            "Training..\n",
            "Training loss:  0.02224760873141166\n",
            "Training metrics:\n",
            "\t accuracy :  0.9932747559823678\n",
            "\t f1 :  [0.9646457  0.99728137 0.95892523 0.9844102  0.97647984]\n",
            "\t average f1 :  0.976348467044366\n",
            "\t confusion matrix :  [[  9618    214     41     41     93]\n",
            " [   152 168926     69     92     44]\n",
            " [    52    136   4354      6     35]\n",
            " [    38    128      9  10924     13]\n",
            " [    74     86     25     19   8075]]\n",
            "Validating..\n",
            "Validation loss:  0.1784186205259175\n",
            "Validation metrics:\n",
            "\t accuracy :  0.9631666870390743\n",
            "\t f1 :  [0.81026625 0.98333733 0.80587276 0.86745067 0.89212373]\n",
            "\t average f1 :  0.8718101486550187\n",
            "\t confusion matrix :  [[ 1689   374    33    65    89]\n",
            " [   94 40956    36    51    27]\n",
            " [   25   208   741    12    21]\n",
            " [   51   438     6  2176    19]\n",
            " [   60   160    16    23  1716]]\n",
            "Epoch #3\n",
            "Training..\n",
            "Training loss:  0.021722196636226508\n",
            "Training metrics:\n",
            "\t accuracy :  0.9931468435138538\n",
            "\t f1 :  [0.96824602 0.9970952  0.9642387  0.97989361 0.97602035]\n",
            "\t average f1 :  0.9770987752339948\n",
            "\t confusion matrix :  [[  9666    201     32     36     72]\n",
            " [   135 168883     73    132     60]\n",
            " [    45    108   4395     13     25]\n",
            " [    42    172      8  10868     21]\n",
            " [    71    103     22     22   8059]]\n",
            "Validating..\n",
            "Validation loss:  0.1730908834930839\n",
            "Validation metrics:\n",
            "\t accuracy :  0.9625351424031292\n",
            "\t f1 :  [0.80837209 0.98326883 0.79957917 0.86435204 0.8929039 ]\n",
            "\t average f1 :  0.8696952061521657\n",
            "\t confusion matrix :  [[ 1738   349    41    57    65]\n",
            " [  113 40903    65    35    48]\n",
            " [   32   190   760    13    12]\n",
            " [   79   448     8  2141    14]\n",
            " [   88   144    20    18  1705]]\n",
            "Epoch #4\n",
            "Training..\n",
            "Training loss:  0.01807727557325487\n",
            "Training metrics:\n",
            "\t accuracy :  0.9946178369017632\n",
            "\t f1 :  [0.97306498 0.99778877 0.96957716 0.98643594 0.98046332]\n",
            "\t average f1 :  0.9814660329758915\n",
            "\t confusion matrix :  [[  9718    156     31     38     61]\n",
            " [   117 168988     55     70     49]\n",
            " [    29    112   4414      8     22]\n",
            " [    43    109      3  10945     12]\n",
            " [    63     81     17     18   8105]]\n",
            "Validating..\n",
            "Validation loss:  0.16426095615073186\n",
            "Validation metrics:\n",
            "\t accuracy :  0.962657376848796\n",
            "\t f1 :  [0.8        0.98467303 0.79339723 0.87655763 0.87922211]\n",
            "\t average f1 :  0.8667700009496443\n",
            "\t confusion matrix :  [[ 1808   268    33    59    82]\n",
            " [  203 40731    76    78    76]\n",
            " [   43   176   745    26    17]\n",
            " [  112   285     2  2251    40]\n",
            " [  104   106    15    32  1718]]\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "train_val_loop_ffnn(\n",
        "    {\n",
        "        \"batch_size\": 512,\n",
        "        \"d_emb\": 64,\n",
        "        \"d_hidden\": 128,\n",
        "        \"window_size\": 2,\n",
        "        \"num_epochs\": 5,\n",
        "        \"learning_rate\": 0.01,\n",
        "        \"l2\": 1e-6,\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h52XPGEg7JOu"
      },
      "source": [
        "Please re-run with `window_size=1`. How does the final performance change?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "TvikQAmC2aW1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68547182-4c52-40ea-8b6a-54ae48096285"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hyperparameters: {'batch_size': 512, 'd_emb': 64, 'd_hidden': 128, 'window_size': 1, 'num_epochs': 5, 'learning_rate': 0.01, 'l2': 1e-06}\n",
            "Loading data from eng.train\n",
            "203621 examples loaded.\n",
            "Loading data from eng.val\n",
            "49086 examples loaded.\n",
            "FFNN(\n",
            "  (embedding): Embedding(20103, 64)\n",
            "  (hidden_layer): Linear(in_features=192, out_features=128, bias=True)\n",
            "  (output_layer): Linear(in_features=128, out_features=5, bias=True)\n",
            ")\n",
            "Epoch #0\n",
            "Training..\n",
            "Training loss:  0.1848342742686458\n",
            "Training metrics:\n",
            "\t accuracy :  0.9463407194584383\n",
            "\t f1 :  [0.73505398 0.97775238 0.71073332 0.82090799 0.7980122 ]\n",
            "\t average f1 :  0.8084919734133628\n",
            "\t confusion matrix :  [[  6707   2014    199    486    604]\n",
            " [   521 167664    153    659    281]\n",
            " [   267   1122   2801    185    211]\n",
            " [   299   1741     50   8842    182]\n",
            " [   445   1139     93    256   6343]]\n",
            "Validating..\n",
            "Validation loss:  0.14784124106517993\n",
            "Validation metrics:\n",
            "\t accuracy :  0.9577679990221244\n",
            "\t f1 :  [0.78193298 0.98153699 0.77735019 0.84670634 0.85931174]\n",
            "\t average f1 :  0.8493676475026785\n",
            "\t confusion matrix :  [[ 1610   389    38    48   165]\n",
            " [   89 40935    48    31    61]\n",
            " [   30   226   707    15    29]\n",
            " [   68   529     6  2063    24]\n",
            " [   71   167    13    26  1698]]\n",
            "Epoch #1\n",
            "Training..\n",
            "Training loss:  0.04028631412008923\n",
            "Training metrics:\n",
            "\t accuracy :  0.9887978195843828\n",
            "\t f1 :  [0.93002371 0.9966739  0.92491694 0.97975891 0.94509332]\n",
            "\t average f1 :  0.9552933552861465\n",
            "\t confusion matrix :  [[  9217    308    107     67    309]\n",
            " [   204 168854     89     71     55]\n",
            " [   110    203   4176     37     61]\n",
            " [    61     84     24  10891     47]\n",
            " [   221    113     47     59   7849]]\n",
            "Validating..\n",
            "Validation loss:  0.14666973456526952\n",
            "Validation metrics:\n",
            "\t accuracy :  0.9596626329299597\n",
            "\t f1 :  [0.77878104 0.98338911 0.7909726  0.869104   0.8627451 ]\n",
            "\t average f1 :  0.8569983668862667\n",
            "\t confusion matrix :  [[ 1725   313    49    76    87]\n",
            " [  194 40701    49   149    71]\n",
            " [   37   182   736    37    15]\n",
            " [   68   297     4  2294    27]\n",
            " [  156   120    16    33  1650]]\n",
            "Epoch #2\n",
            "Training..\n",
            "Training loss:  0.028698991985301903\n",
            "Training metrics:\n",
            "\t accuracy :  0.9913117915617129\n",
            "\t f1 :  [0.94782346 0.99693626 0.95371083 0.98191983 0.96171035]\n",
            "\t average f1 :  0.9684201487429969\n",
            "\t confusion matrix :  [[  9428    259     75     44    200]\n",
            " [   194 168882     64     96     55]\n",
            " [    60    132   4337     16     34]\n",
            " [    48    137      7  10889     24]\n",
            " [   158    101     33     29   7962]]\n",
            "Validating..\n",
            "Validation loss:  0.17877042429851522\n",
            "Validation metrics:\n",
            "\t accuracy :  0.9586643849570142\n",
            "\t f1 :  [0.79624277 0.98095991 0.80501089 0.83858998 0.87424837]\n",
            "\t average f1 :  0.8590103846611242\n",
            "\t confusion matrix :  [[ 1653   411    32    47   107]\n",
            " [   86 40959    45    36    38]\n",
            " [   28   198   739    24    18]\n",
            " [   62   578     1  2034    15]\n",
            " [   73   198    12    20  1672]]\n",
            "Epoch #3\n",
            "Training..\n",
            "Training loss:  0.02723860046685549\n",
            "Training metrics:\n",
            "\t accuracy :  0.9914052660579346\n",
            "\t f1 :  [0.95570861 0.99659988 0.95456541 0.97883478 0.96508397]\n",
            "\t average f1 :  0.9701585314147714\n",
            "\t confusion matrix :  [[  9505    243     50     47    157]\n",
            " [   160 168830     98    122     68]\n",
            " [    47    153   4349     16     26]\n",
            " [    43    185      5  10845     27]\n",
            " [   134    123     19     24   7988]]\n",
            "Validating..\n",
            "Validation loss:  0.17224322918142812\n",
            "Validation metrics:\n",
            "\t accuracy :  0.9592144399625148\n",
            "\t f1 :  [0.77802414 0.98251803 0.80827887 0.84493237 0.8687712 ]\n",
            "\t average f1 :  0.8565049205174201\n",
            "\t confusion matrix :  [[ 1579   388    32   143   108]\n",
            " [   64 40943    38    71    48]\n",
            " [   23   201   742    21    20]\n",
            " [   56   462     0  2155    17]\n",
            " [   87   185    17    21  1665]]\n",
            "Epoch #4\n",
            "Training..\n",
            "Training loss:  0.023851962553651566\n",
            "Training metrics:\n",
            "\t accuracy :  0.9925171205919395\n",
            "\t f1 :  [0.95986706 0.99723734 0.95842019 0.98218554 0.96772637]\n",
            "\t average f1 :  0.9730872997788355\n",
            "\t confusion matrix :  [[  9531    221     54     42    154]\n",
            " [   120 168934     73     96     56]\n",
            " [    48    131   4368     10     32]\n",
            " [    44    140      7  10889     30]\n",
            " [   114     99     24     26   8021]]\n",
            "Validating..\n",
            "Validation loss:  0.15807741938260733\n",
            "Validation metrics:\n",
            "\t accuracy :  0.9596015157071263\n",
            "\t f1 :  [0.7839196  0.9833034  0.80237581 0.84940239 0.87539767]\n",
            "\t average f1 :  0.8588797722728622\n",
            "\t confusion matrix :  [[ 1794   295    31    50    80]\n",
            " [  188 40783    62    95    36]\n",
            " [   48   179   743    22    15]\n",
            " [  174   368     1  2132    15]\n",
            " [  123   162     8    31  1651]]\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "train_val_loop_ffnn(\n",
        "    {\n",
        "        \"batch_size\": 512,\n",
        "        \"d_emb\": 64,\n",
        "        \"d_hidden\": 128,\n",
        "        \"window_size\": 1,\n",
        "        \"num_epochs\": 5,\n",
        "        \"learning_rate\": 0.01,\n",
        "        \"l2\": 1e-6,\n",
        "    }\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGgA0zExVtg9"
      },
      "source": [
        "### Question **(1 point)**\n",
        "\n",
        "If everything works as expected, you should see the loss decrease and the accuracy increase for both training and validation. The final accuracy can be pretty high; you should probably debug if it's below 92%. However, **is accuracy a good metric for this problem? Why?**. Hint: look at the F1 scores for different tags and the confusion matrix.\n",
        "\n",
        "**TODO: Please fill in your answer here**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy alone might not be the best metric for evaluating Named Entity Recognition (NER) models because it doesn't take into account the class imbalance and the importance of different classes. In NER tasks, the classes (NER tags) might be imbalanced, meaning some classes occur more frequently than others in the dataset.\n",
        "\n",
        "F1 score is often a better metric for NER tasks because it considers both precision and recall. Precision measures the proportion of correctly predicted instances among all instances predicted as positive, while recall measures the proportion of correctly predicted instances among all actual positive instances. F1 score is the harmonic mean of precision and recall, giving a balanced measure between the two.\n",
        "\n",
        "Additionally, looking at F1 scores for different tags and the confusion matrix can provide insights into the model's performance for each tag individually. This is important because different tags might have different levels of difficulty in prediction. For example, some tags might be rare in the dataset and therefore harder to predict accurately.\n",
        "\n",
        "The confusion matrix shows how often each class is misclassified as another class, which can help identify specific patterns of errors made by the model. For example, it can reveal if certain tags are consistently confused with each other, indicating areas for improvement in the model or the data preprocessing."
      ],
      "metadata": {
        "id": "3xM7WJz8cdhk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aF-aiPJ4JRbW"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}